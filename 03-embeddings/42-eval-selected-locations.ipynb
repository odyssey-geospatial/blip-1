{"cells":[{"cell_type":"markdown","id":"3e2daeab-4b8b-411b-84cc-dd88286bf67b","metadata":{"id":"3e2daeab-4b8b-411b-84cc-dd88286bf67b"},"source":["# Apply the trained embedding model to selected locations\n","\n","The real purpose of this notebook is to develop and end-to-end process\n","to pull geo data, get MPP encodings, and then apply the initial and\n","final embedding models."]},{"cell_type":"markdown","id":"9fdc7f7f-2399-4755-b7db-052b0132479a","metadata":{"id":"9fdc7f7f-2399-4755-b7db-052b0132479a"},"source":["## Processing Setup"]},{"cell_type":"code","execution_count":9,"id":"5856a24c-41a8-45fe-b254-8e4c31b330d9","metadata":{"id":"5856a24c-41a8-45fe-b254-8e4c31b330d9","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1755262692261,"user_tz":240,"elapsed":7979,"user":{"displayName":"John Collins","userId":"16643596247369517939"}},"outputId":"0c2b7fbe-aa2b-455e-9d22-ae95b6e53c8b"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n","Collecting geo_encodings\n","  Downloading geo_encodings-1.0.4-py2.py3-none-any.whl.metadata (4.0 kB)\n","Requirement already satisfied: shapely in /usr/local/lib/python3.11/dist-packages (from geo_encodings) (2.1.1)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from geo_encodings) (1.16.1)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from geo_encodings) (2.0.2)\n","Downloading geo_encodings-1.0.4-py2.py3-none-any.whl (6.9 kB)\n","Installing collected packages: geo_encodings\n","Successfully installed geo_encodings-1.0.4\n"]}],"source":["# Google colab\n","import os\n","from google.colab import drive\n","drive.mount('/content/drive')\n","project_home = '/content/drive/MyDrive/Projects/verge'\n","os.chdir(project_home)\n","!pip install geo_encodings"]},{"cell_type":"code","source":[],"metadata":{"id":"HuAGOe3Vztx4"},"id":"HuAGOe3Vztx4","execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"id":"96eefe45-43a4-4665-8b29-484e2b32ae66","metadata":{"id":"96eefe45-43a4-4665-8b29-484e2b32ae66"},"outputs":[],"source":["# Local processing setup\n","# project_home = '..'"]},{"cell_type":"markdown","id":"928178a0-d593-4266-a683-5f9c5e3830ba","metadata":{"id":"928178a0-d593-4266-a683-5f9c5e3830ba"},"source":["## Notebook Setup"]},{"cell_type":"code","execution_count":5,"id":"45908146-a047-477f-9f71-a417b5bc1c0e","metadata":{"id":"45908146-a047-477f-9f71-a417b5bc1c0e","executionInfo":{"status":"ok","timestamp":1755262605210,"user_tz":240,"elapsed":10,"user":{"displayName":"John Collins","userId":"16643596247369517939"}}},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","from torch.utils.data import DataLoader, Dataset\n","from typing import List, Tuple, Optional\n","\n","import pickle\n","import json\n","import pandas as pd\n","import numpy as np\n","\n","import sys\n","sys.path.append('%s/03-embeddings' % project_home)\n","from embedderv5 import *"]},{"cell_type":"markdown","id":"48aa408e-db4c-4f59-8a22-993ee4ec5a85","metadata":{"id":"48aa408e-db4c-4f59-8a22-993ee4ec5a85"},"source":["## Parameters"]},{"cell_type":"code","execution_count":3,"id":"6886ae2e-4c09-4a9d-8104-5fd506c75ad8","metadata":{"id":"6886ae2e-4c09-4a9d-8104-5fd506c75ad8","executionInfo":{"status":"ok","timestamp":1755262578859,"user_tz":240,"elapsed":6,"user":{"displayName":"John Collins","userId":"16643596247369517939"}}},"outputs":[],"source":["# The name of the ROI to use.\n","roi_name = 'newengland'\n","\n","# The name of the general-purpose data directory.\n","data_home = '%s/data' % (project_home)\n","\n","# The name of the ROI-specific data directory.\n","roi_home = '%s/data/%s' % (project_home, roi_name)\n","\n","# The unique identifier of the model to be used.\n","run_id = '201b'\n","\n","# Identifier of the splits file.\n","splits_id = '201'\n","\n"]},{"cell_type":"markdown","source":["## Preliminaries"],"metadata":{"id":"6WbnmtGQy6dt"},"id":"6WbnmtGQy6dt"},{"cell_type":"code","source":["# Read the ROI definition.\n","fname = '%s/roi.json' % roi_home\n","with open(fname) as source:\n","    roi = json.load(source)\n","\n","tile_size = roi['tile_size']\n","encoding_resolution = roi['encoding_resolution']\n","\n","roi\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7PWm1IxGy5YD","executionInfo":{"status":"ok","timestamp":1755262609664,"user_tz":240,"elapsed":613,"user":{"displayName":"John Collins","userId":"16643596247369517939"}},"outputId":"d1840ef4-db12-46f7-f408-a758664f10c8"},"id":"7PWm1IxGy5YD","execution_count":6,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'name': 'newengland',\n"," 'lon0': -73.564321,\n"," 'lat0': 41.253746,\n"," 'lon1': -68.058533,\n"," 'lat1': 45.116468,\n"," 'proj_def': '\\n+proj=tmerc +lat_0=43.185107 +lon_0=-70.81142700000001\\n+k=1.0 +x_0=231000.0 +y_0=211000.0 +datum=WGS84 +units=m +no_defs\\n',\n"," 'tile_size': 2000,\n"," 'tile_shift': 1000,\n"," 'encoding_resolution': 100}"]},"metadata":{},"execution_count":6}]},{"cell_type":"code","source":["# Define an encoder to use.\n","from geo_encodings import MPPEncoder\n","encoder = MPPEncoder(\n","    region=[0, 0, tile_size, tile_size],\n","    resolution=encoding_resolution,\n","    center=True\n",")\n","geo_encoding_dim = len(encoder)\n","print('%d elements in encodings' % geo_encoding_dim)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bh6WkUcZzFm3","executionInfo":{"status":"ok","timestamp":1755262705834,"user_tz":240,"elapsed":821,"user":{"displayName":"John Collins","userId":"16643596247369517939"}},"outputId":"02095837-3cb2-4896-c030-c46e8bca3860"},"id":"bh6WkUcZzFm3","execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["400 elements in encodings\n"]}]},{"cell_type":"markdown","id":"13ffc010-4ee2-43ad-b82f-0bfb063c0de7","metadata":{"id":"13ffc010-4ee2-43ad-b82f-0bfb063c0de7"},"source":["## Processing\n"]},{"cell_type":"code","source":["# Set a lon/lat for the center of a tile\n","center_lat, center_lon = 43.000659, -70.921196 # Stratham BMW\n"],"metadata":{"id":"DpWSFGxIz9Vn","executionInfo":{"status":"ok","timestamp":1755262753489,"user_tz":240,"elapsed":3,"user":{"displayName":"John Collins","userId":"16643596247369517939"}}},"id":"DpWSFGxIz9Vn","execution_count":11,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"X1tjsEFMz9NS"},"id":"X1tjsEFMz9NS","execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"CzqNVDOTz9DH"},"id":"CzqNVDOTz9DH","execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"id":"b377b4b0-8101-4ac8-88b9-547570f3b741","metadata":{"id":"b377b4b0-8101-4ac8-88b9-547570f3b741"},"outputs":[],"source":["# We will divide into training and validation sets based on AOI.\n","# The splits have already been determined, before training the initial MGM.\n","# Here we look them up and re-organize things a bit.\n","fname = '%s/models/splits-%s.csv' % (roi_home, splits_id)\n","splits = pd.read_csv(fname)\n","print('%d splits' % len(splits))\n","splits.head(3)\n","\n","splits_lookup = {\n","    '%s : %s' % (z['aoi_tag'], z['tile_tag']): z['split']\n","    for k, z in splits.iterrows()\n","}\n","print('%d elements in splits lookup' % len(splits_lookup))\n"]},{"cell_type":"code","execution_count":null,"id":"2a047a46-74d7-426a-ac1a-502f8770eda6","metadata":{"id":"2a047a46-74d7-426a-ac1a-502f8770eda6"},"outputs":[],"source":["# Get a list of tiles.\n","fname = '%s/tiles.csv' % roi_home\n","tile_info = pd.read_csv(fname)\n","print('%d tiles' % len(tile_info))\n","\n","# Make a lookup table for tile info.\n","tile_info_lookup = {\n","    '%s : %s' % (z['aoi_tag'], z['tile_tag']): z\n","    for z in tile_info.to_dict('records')\n","}"]},{"cell_type":"code","execution_count":null,"id":"038c2578-f48e-4b78-922a-e6e2829a7fb5","metadata":{"id":"038c2578-f48e-4b78-922a-e6e2829a7fb5"},"outputs":[],"source":["# Get the list of AOI tags.\n","aoi_tags = np.unique(tile_info['aoi_tag'])\n","print('%d unique AOIs' % len(aoi_tags))"]},{"cell_type":"code","execution_count":null,"id":"2c0c2b64-203f-42c6-b5b8-8d15ea3cca7d","metadata":{"id":"2c0c2b64-203f-42c6-b5b8-8d15ea3cca7d"},"outputs":[],"source":["# Load final embeddings.\n","embeddings_lookup = {}\n","\n","fname = '%s/embeddings/embeddings-%s.pkl' % (roi_home, run_id)\n","with open(fname, 'rb') as source:\n","    a = pickle.load(source)\n","\n","print('%d total embeddings' % len(a))\n"]},{"cell_type":"code","execution_count":null,"id":"a9c50cfe-f126-45e8-ad9f-ead1406c303a","metadata":{"id":"a9c50cfe-f126-45e8-ad9f-ead1406c303a"},"outputs":[],"source":["embedding_dim = a[0]['embedding'].shape[-1]\n","print('dimension of embeddings is %d' % embedding_dim)"]},{"cell_type":"code","source":["a[0]"],"metadata":{"id":"6PEXc6DVoJnW"},"id":"6PEXc6DVoJnW","execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Reorganize those.\n","idents = []\n","embedding_list = []\n","for rec in a:\n","  idents.append('%s : %s' % (rec['aoi_tag'], rec['tile_tag']))\n","  embedding_list.append(rec['embedding'])\n","\n","embeddings = np.vstack(embedding_list)\n","print(embeddings.shape)\n","print(len(idents))"],"metadata":{"id":"g5wvTa_yo7VA"},"id":"g5wvTa_yo7VA","execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Pick a random embedding.\n","n = len(idents)\n","ix = np.random.choice(n)\n","print(ix)\n","\n","# Compute distance between the selected embedding and all other embeddings.\n","dd = np.linalg.norm(embeddings - embeddings[ix], axis=1)\n","\n","reix = np.argsort(dd)\n","print(reix[:20])\n","print(dd[reix[:20]])\n","\n","ix0 = ix\n","ix1 = reix[1]\n","\n","ident_0 = idents[ix0]\n","ident_1 = idents[ix1]\n","embed_0 = embeddings[0]\n","embed_1 = embeddings[1]\n","info_0 = tile_info_lookup[ident_0]\n","info_1 = tile_info_lookup[ident_1]\n","print(info_0)\n","print(info_1)"],"metadata":{"id":"7446mcwKpS84"},"id":"7446mcwKpS84","execution_count":null,"outputs":[]},{"cell_type":"code","source":["import folium\n","\n","# Create a map centered between the two tiles\n","center_lat = (info_0['center_lat'] + info_1['center_lat']) / 2\n","center_lon = (info_0['center_lon'] + info_1['center_lon']) / 2\n","m = folium.Map(location=[center_lat, center_lon], zoom_start=10,\n","               width=800, height=500)\n","\n","# Add bounding box for info_0\n","folium.Rectangle(\n","    bounds=[[info_0['lat0'], info_0['lon0']], [info_0['lat1'], info_0['lon1']]],\n","    color='blue',\n","    fill=True,\n","    fill_color='blue',\n","    fill_opacity=0.2,\n","    tooltip=ident_0\n",").add_to(m)\n","\n","# Add bounding box for info_1\n","folium.Rectangle(\n","    bounds=[[info_1['lat0'], info_1['lon0']], [info_1['lat1'], info_1['lon1']]],\n","    color='red',\n","    fill=True,\n","    fill_color='red',\n","    fill_opacity=0.2,\n","    tooltip=ident_1\n",").add_to(m)\n","\n","# Display the map\n","display(m)"],"metadata":{"id":"XiMSCcw1r22l"},"id":"XiMSCcw1r22l","execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Clustering"],"metadata":{"id":"WlKxxSvVStWG"},"id":"WlKxxSvVStWG"},{"cell_type":"code","source":["from sklearn.cluster import KMeans\n","\n","# Define the number of clusters\n","n_clusters = 5\n","\n","# Initialize and fit the KMeans model\n","kmeans = KMeans(n_clusters=n_clusters, random_state=0, n_init=10)\n","cluster_labels = kmeans.fit_predict(embeddings)\n","\n","# Print the cluster labels\n","print(cluster_labels)"],"metadata":{"id":"XEHpdKb3sgeW"},"id":"XEHpdKb3sgeW","execution_count":null,"outputs":[]},{"cell_type":"code","source":["import folium\n","import pandas as pd\n","\n","# Create a map centered on the approximate center of the data\n","# (using the first tile as a starting point)\n","if idents:\n","    first_tile_info = tile_info_lookup[idents[0]]\n","    m = folium.Map(location=[first_tile_info['center_lat'], first_tile_info['center_lon']], zoom_start=6, width=800, height=500)\n","else:\n","    m = folium.Map(location=[0, 0], zoom_start=2, width=800, height=500) # Default map if no idents\n","\n","# Define a color map for the clusters\n","# You can adjust the colors based on the number of clusters\n","colors = [\n","    'red', 'blue', 'green', 'purple', 'orange', 'darkred',\n","    'lightred', 'beige', 'darkblue', 'darkgreen', 'cadetblue',\n","    'darkpurple', 'white', 'pink', 'lightblue', 'lightgreen',\n","    'gray', 'black', 'lightgray', 'gold'\n","]\n","\n","# Ensure enough colors for the number of clusters\n","if n_clusters > len(colors):\n","    print(f\"Warning: Not enough colors defined for {n_clusters} clusters. Using repeating colors.\")\n","    colors = (colors * ((n_clusters // len(colors)) + 1))[:n_clusters]\n","\n","\n","# Add each tile to the map with its cluster color\n","for i, ident in enumerate(idents):\n","    tile_info = tile_info_lookup[ident]\n","    cluster = cluster_labels[i]\n","    color = colors[cluster]\n","\n","    # radius = 10  # Adjust the radius as needed\n","    # folium.CircleMarker(\n","    #     location=[tile_info['center_lat'], tile_info['center_lon']],\n","    #     radius=radius,\n","    #     color=color,\n","    #     stroke=False,\n","    #     fill=True,\n","    #     fill_opacity=0.6,\n","    #     opacity=1,\n","    # ).add_to(m)\n","\n","    folium.Rectangle(\n","        bounds=[[tile_info['lat0'], tile_info['lon0']], [tile_info['lat1'], tile_info['lon1']]],\n","        color=color,\n","        fill=True,\n","        fill_color=color,\n","        fill_opacity=0.4,\n","        tooltip=f\"Tile: {ident}, Cluster: {cluster}\"\n","    ).add_to(m)\n","\n","# Display the map\n","display(m)"],"metadata":{"id":"Uvc1xXLzTBEp"},"id":"Uvc1xXLzTBEp","execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"7d1jVi51VRy_"},"id":"7d1jVi51VRy_","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.1"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":5}