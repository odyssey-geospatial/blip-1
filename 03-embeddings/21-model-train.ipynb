{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3e2daeab-4b8b-411b-84cc-dd88286bf67b",
   "metadata": {},
   "source": [
    "# Train the embedding model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fdc7f7f-2399-4755-b7db-052b0132479a",
   "metadata": {},
   "source": [
    "## Processing Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5856a24c-41a8-45fe-b254-8e4c31b330d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Google colab\n",
    "# import os\n",
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')\n",
    "# project_home = '/content/drive/MyDrive/Projects/verge'\n",
    "# os.chdir(project_home)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96eefe45-43a4-4665-8b29-484e2b32ae66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Local processing setup\n",
    "project_home = '..'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "928178a0-d593-4266-a683-5f9c5e3830ba",
   "metadata": {},
   "source": [
    "## Notebook Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45908146-a047-477f-9f71-a417b5bc1c0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import numpy as np\n",
    "from typing import List, Tuple, Optional\n",
    "\n",
    "import pickle\n",
    "import pandas as pd\n",
    "\n",
    "from embedderv5 import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48aa408e-db4c-4f59-8a22-993ee4ec5a85",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6886ae2e-4c09-4a9d-8104-5fd506c75ad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The name of the ROI to use.\n",
    "roi_name = 'ne-laptop'\n",
    "\n",
    "# The name of the general-purpose data directory.\n",
    "data_home = '%s/data' % (project_home)\n",
    "\n",
    "# The name of the ROI-specific data directory.\n",
    "roi_home = '%s/data/%s' % (project_home, roi_name)\n",
    "\n",
    "# The unique identifier of the model to be used.\n",
    "run_id = '102'\n",
    "\n",
    "# What type of device to train on.\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print('using device', device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13ffc010-4ee2-43ad-b82f-0bfb063c0de7",
   "metadata": {},
   "source": [
    "## Load and organize data\n",
    "We have two data sources that we need to associate with one another:\n",
    "a set of initial embeddings (\"initials\") and a set of feature vectors\n",
    "to be used for similarity assessments (\"features\")."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b377b4b0-8101-4ac8-88b9-547570f3b741",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will divide into training and validation sets based on AOI. \n",
    "# The splits have already been determined, before training the initial MGM.\n",
    "# Here we look them up and re-organize things a bit.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a047a46-74d7-426a-ac1a-502f8770eda6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a list of tiles.\n",
    "fname = '%s/tiles.csv' % roi_home\n",
    "tile_info = pd.read_csv(fname)\n",
    "print('%d tiles' % len(tile_info))\n",
    "tile_info.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "038c2578-f48e-4b78-922a-e6e2829a7fb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the list of AOI tags.\n",
    "aoi_tags = np.unique(tile_info['aoi_tag'])\n",
    "print('%d unique AOIs' % len(aoi_tags))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c0c2b64-203f-42c6-b5b8-8d15ea3cca7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load initial embeddings. Put them into a lookup table based on aoi/tile identifiers.\n",
    "embeddings_lookup = {}\n",
    "\n",
    "for aoi_tag in aoi_tags:\n",
    "\n",
    "    fname = '%s/initials/%s.pkl' % (roi_home, aoi_tag)\n",
    "    with open(fname, 'rb') as source:\n",
    "        a = pickle.load(source)\n",
    "    for b in a:\n",
    "        key = '%s : %s' % (b['aoi_tag'], b['tile_tag'])\n",
    "        e = b['embedding']\n",
    "        embeddings_lookup[key] = e\n",
    "\n",
    "print('%d total embeddings' % len(embeddings_lookup))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9c50cfe-f126-45e8-ad9f-ead1406c303a",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dim = e.shape[-1]\n",
    "print('dimension of embeddings is %d' % embedding_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "199d516d-0071-4acd-9be5-363d10e38d69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load initial Features. Ditto.\n",
    "features_lookup = {}\n",
    "\n",
    "for aoi_tag in aoi_tags:\n",
    "\n",
    "    fname = '%s/features/%s.pkl' % (roi_home, aoi_tag)\n",
    "    with open(fname, 'rb') as source:\n",
    "        a = pickle.load(source)\n",
    "    for b in a:\n",
    "        key = '%s : %s' % (b['aoi_tag'], b['tile_tag'])\n",
    "        f = b['features']\n",
    "        features_lookup[key] = f\n",
    "\n",
    "print('%d total feature vectors' % len(features_lookup))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0938625d-a7b7-47ac-807f-b726d3bae9cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Organize the data the way the model expects it.\n",
    "sequences = []\n",
    "similarity_features = []\n",
    "for key in features_lookup.keys():\n",
    "    f = features_lookup[key]\n",
    "    if key in embeddings_lookup:\n",
    "        e = embeddings_lookup[key].squeeze().detach().numpy()\n",
    "        sequences.append(e)\n",
    "        similarity_features.append(f)\n",
    "    else:\n",
    "        print('key mismatch: %s' % key)\n",
    "\n",
    "print(type(sequences))\n",
    "print(type(sequences[0]))\n",
    "print(sequences[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b1179dc-ea51-4da9-bafc-c457f6004b82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # # This was the Claude-generated code to generate test data for the model. \n",
    "# sequences, similarity_features = generate_sample_data(\n",
    "#     num_instances=1000, min_R=5, max_R=20, C=32, similarity_dim=16\n",
    "# )\n",
    "# print(type(sequences))\n",
    "# print(type(sequences[0]))\n",
    "# print(sequences[0].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd5c18a8-ba3c-4a08-82ae-c2bdfc079075",
   "metadata": {},
   "source": [
    "## Model\n",
    "The model code, including data loaders, the model itself, loss function, and all that,\n",
    "were generated by Claude via a lot of iterative prompting and debugging.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3479dc83-3452-4c86-a745-a6ba96a9df68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataset and dataloader with explicit triplet sampling\n",
    "dataset = ContrastivePairDataset(\n",
    "    sequences, \n",
    "    similarity_features, \n",
    "    similarity_threshold=0.5,  # Adjust based on your similarity features\n",
    "    num_negatives=2  # Number of negatives per anchor\n",
    ")\n",
    "train_loader = DataLoader(dataset, batch_size=32, shuffle=True, collate_fn=triplet_collate_fn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cc2d22a-0ac0-4a11-a75d-b95811a398d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize model\n",
    "model = PermutationInvariantModel(\n",
    "    input_dim=embedding_dim,\n",
    "    hidden_dim=128,\n",
    "    embedding_dim=embedding_dim,\n",
    "    num_attention_heads=4,  # Now using 4 attention heads\n",
    "    num_linear_layers=3,\n",
    "    dropout=0.1\n",
    ")\n",
    "\n",
    "print(f\"Model has {sum(p.numel() for p in model.parameters())} parameters\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb966d9b-f8f9-4067-84a1-09016d764c24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "train_model(model, train_loader, num_epochs=50, learning_rate=1e-3, device=device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63cb371f-21f6-4296-af2d-135e7b48cd0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Example inference\n",
    "# model.eval()\n",
    "# with torch.no_grad():\n",
    "#     sample_batch = next(iter(train_loader))\n",
    "#     # Unpack the dictionary structure from triplet data loader\n",
    "#     anchor_seqs, anchor_masks, anchor_sims = sample_batch['anchor']\n",
    "#     anchor_seqs = anchor_seqs.to(device)\n",
    "#     anchor_masks = anchor_masks.to(device)\n",
    "    \n",
    "#     # Generate embeddings for anchor samples\n",
    "#     embeddings = model(anchor_seqs, anchor_masks)\n",
    "#     print(f\"Generated embeddings shape: {embeddings.shape}\")\n",
    "#     print(f\"Sample embedding norm: {torch.norm(embeddings[0]).item():.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e59d389-35e8-407f-888c-724ff2e59cf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "        \n",
    "# Example inference\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    sample_batch = next(iter(train_loader))\n",
    "    # Unpack the dictionary structure from triplet data loader\n",
    "    anchor_seqs, anchor_masks, anchor_sims = sample_batch['anchor']\n",
    "    anchor_seqs = anchor_seqs.to(device)\n",
    "    anchor_masks = anchor_masks.to(device)\n",
    "    \n",
    "    # Generate embeddings for anchor samples\n",
    "    embeddings = model(anchor_seqs, anchor_masks)\n",
    "    print(f\"Generated embeddings shape: {embeddings.shape}\")\n",
    "    print(f\"Sample embedding norm: {torch.norm(embeddings[0]).item():.4f}\")\n",
    "    \n",
    "    # Get embeddings for positives\n",
    "    pos_seqs, pos_masks, pos_sims = sample_batch['positive']\n",
    "    pos_seqs, pos_masks = pos_seqs.to(device), pos_masks.to(device)\n",
    "    pos_embeddings = model(pos_seqs, pos_masks)\n",
    "    print(f\"Positive embeddings shape: {pos_embeddings.shape}\")\n",
    "    \n",
    "    # Get embeddings for negatives\n",
    "    neg_seqs, neg_masks, neg_sims, neg_batch_indices = sample_batch['negatives']\n",
    "    neg_seqs, neg_masks = neg_seqs.to(device), neg_masks.to(device)\n",
    "    neg_batch_indices = neg_batch_indices.to(device)\n",
    "    neg_embeddings = model(neg_seqs, neg_masks)\n",
    "    print(f\"Negative embeddings shape: {neg_embeddings.shape}\")\n",
    "    \n",
    "    # Check similarity between anchors and positives\n",
    "    pos_similarities = F.cosine_similarity(embeddings, pos_embeddings, dim=1)\n",
    "    print(f\"Anchor-Positive similarities: {pos_similarities.mean().item():.4f} ± {pos_similarities.std().item():.4f}\")\n",
    "    \n",
    "    # Check similarity between anchors and negatives\n",
    "    batch_size = embeddings.shape[0]\n",
    "    neg_similarities_all = []\n",
    "    \n",
    "    for i in range(batch_size):\n",
    "        # Get negatives for this anchor\n",
    "        neg_mask = neg_batch_indices == i\n",
    "        if neg_mask.sum() > 0:\n",
    "            anchor_i = embeddings[i:i+1]  # (1, embedding_dim)\n",
    "            negatives_i = neg_embeddings[neg_mask]  # (num_negs, embedding_dim)\n",
    "            \n",
    "            # Compute similarities between this anchor and its negatives\n",
    "            neg_sims_i = F.cosine_similarity(\n",
    "                anchor_i.expand_as(negatives_i), negatives_i, dim=1\n",
    "            )\n",
    "            neg_similarities_all.extend(neg_sims_i.cpu().tolist())\n",
    "    \n",
    "    if len(neg_similarities_all) > 0:\n",
    "        neg_similarities = torch.tensor(neg_similarities_all)\n",
    "        print(f\"Anchor-Negative similarities: {neg_similarities.mean().item():.4f} ± {neg_similarities.std().item():.4f}\")\n",
    "        \n",
    "        # Show the difference (should be positive if model is learning well)\n",
    "        print(f\"Positive vs Negative similarity difference: {pos_similarities.mean().item() - neg_similarities.mean().item():.4f}\")\n",
    "    else:\n",
    "        print(\"No negative samples found in this batch\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
