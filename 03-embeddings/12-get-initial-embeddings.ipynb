{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e86b8916-bdd0-46e6-8195-8de0a4a06ab4",
   "metadata": {
    "id": "e86b8916-bdd0-46e6-8195-8de0a4a06ab4"
   },
   "source": [
    "### VERGE: Vector-Mode Regional Geospatial Encoding\n",
    "# Initial Embeddings \n",
    "\n",
    "Back in the \"02\" folder, we trained a Masked Geospatial Model.\n",
    "That model can compute a set of embeddings for any tile, \n",
    "for which the inputs are a set of geospatial entities. \n",
    "Thise embeddings are permutation-equivariant (\"perm-e\") \n",
    "with respect to the input features. In thi folder we are building \n",
    "a fully permutation-invariant (\"perm-i\") aggregation of the perm-e\n",
    "outputs. \n",
    "\n",
    "In this notebook, we compute those perm-e embeddings for all instances\n",
    "in our training and validation datasets.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8M2z1JqEbum-",
   "metadata": {
    "id": "8M2z1JqEbum-"
   },
   "source": [
    "## Processing Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "SDCVXcwwbuNz",
   "metadata": {
    "id": "SDCVXcwwbuNz"
   },
   "outputs": [],
   "source": [
    "# Google colab setup\n",
    "# import os\n",
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')\n",
    "# project_home = '/content/drive/MyDrive/Projects/verge'\n",
    "# os.chdir(project_home)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "jfRkhxK615Hn",
   "metadata": {
    "id": "jfRkhxK615Hn"
   },
   "outputs": [],
   "source": [
    "# !pip install geo_encodings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "i_mx-hmv1fmE",
   "metadata": {
    "id": "i_mx-hmv1fmE"
   },
   "outputs": [],
   "source": [
    "# Local processing setup\n",
    "project_home = '..'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "L4cSLLSy1jCL",
   "metadata": {
    "id": "L4cSLLSy1jCL"
   },
   "source": [
    "## Notebook Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b54d7995-33a4-44b6-a248-4d97c86ce57c",
   "metadata": {
    "id": "b54d7995-33a4-44b6-a248-4d97c86ce57c"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "import pickle\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.utils\n",
    "import torch.utils.data\n",
    "from torch.utils.data import DataLoader\n",
    "import copy\n",
    "import json\n",
    "from geo_encodings import MPPEncoder\n",
    "\n",
    "import sys\n",
    "sys.path.append(project_home)\n",
    "from utils.geo_transformer_mem import VergeDataset, verge_collate_fn, GeospatialTransformer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "445ca7e3-ead1-4ddd-b908-e3ecf2d2aef2",
   "metadata": {
    "id": "445ca7e3-ead1-4ddd-b908-e3ecf2d2aef2"
   },
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "faeed93f-aa96-4f8b-8865-507f58adf0b3",
   "metadata": {
    "id": "faeed93f-aa96-4f8b-8865-507f58adf0b3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using device cpu\n"
     ]
    }
   ],
   "source": [
    "# The name of the ROI to use.\n",
    "roi_name = 'ne-laptop'\n",
    "\n",
    "# The name of the general-purpose data directory.\n",
    "data_home = '%s/data' % (project_home)\n",
    "\n",
    "# The name of the ROI-specific data directory.\n",
    "roi_home = '%s/data/%s' % (project_home, roi_name)\n",
    "\n",
    "# The unique identifier of the model to be used.\n",
    "run_id = '101'\n",
    "\n",
    "# What type of device to train on.\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print('using device', device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae4c1f54-443b-4820-ae36-b00ed6d575d1",
   "metadata": {
    "id": "ae4c1f54-443b-4820-ae36-b00ed6d575d1"
   },
   "source": [
    "## Preliminaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "12061fe8-4f75-48bb-9eb3-06216f7b8e74",
   "metadata": {
    "id": "12061fe8-4f75-48bb-9eb3-06216f7b8e74"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "400 elements in encodings\n"
     ]
    }
   ],
   "source": [
    "# Read the ROI definition.\n",
    "fname = '%s/roi.json' % roi_home\n",
    "with open(fname) as source:\n",
    "    roi = json.load(source)\n",
    "\n",
    "tile_size = roi['tile_size']\n",
    "encoding_resolution = roi['encoding_resolution']\n",
    "\n",
    "# We need the dimension of the encoding.\n",
    "encoder = MPPEncoder(\n",
    "    region=[0, 0, tile_size, tile_size],\n",
    "    resolution=encoding_resolution,\n",
    "    center=True\n",
    ")\n",
    "geo_encoding_dim = len(encoder)\n",
    "print('%d elements in encodings' % geo_encoding_dim)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d216238e-a075-4a1d-81cf-3269d8c82fb8",
   "metadata": {
    "id": "d216238e-a075-4a1d-81cf-3269d8c82fb8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22 labels in this dataset\n"
     ]
    }
   ],
   "source": [
    "# Read the list of labels.\n",
    "fname = '%s/labels.csv' % data_home\n",
    "labels = pd.read_csv(fname)\n",
    "n_classes = len(labels)\n",
    "print('%d labels in this dataset' % n_classes)\n",
    "\n",
    "label_id_lookup = {\n",
    "    z['label']: z['id']\n",
    "    for z in labels.to_dict('records')\n",
    "}\n",
    "\n",
    "label_name_lookup = {\n",
    "    z['id']: z['label']\n",
    "    for z in labels.to_dict('records')\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d86rIhLz3w72",
   "metadata": {
    "id": "d86rIhLz3w72"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22 class info records\n"
     ]
    }
   ],
   "source": [
    "# Read the file that gives class probabilities.\n",
    "fname = '%s/class_info.csv' % roi_home\n",
    "class_info = pd.read_csv(fname)\n",
    "print('%d class info records' % len(class_info))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "PGWG-XHKFLmq",
   "metadata": {
    "id": "PGWG-XHKFLmq"
   },
   "source": [
    "## Load data\n",
    "We determine which files to read by loading the associated \"split\" file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2f4b1ff1-08bd-44f6-9d42-9cf7c142d498",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the list of AOI tags. They can be found in the splits file.\n",
    "fname = '%s/models/splits-%s.csv' % (roi_home, run_id)\n",
    "splits = pd.read_csv(fname)\n",
    "aoi_tags = np.unique(splits['aoi_tag'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa310216-b622-42e2-a551-322943108993",
   "metadata": {
    "id": "fa310216-b622-42e2-a551-322943108993"
   },
   "source": [
    "## Prep model and data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3be7cab2-c69b-47cd-a574-09011c06d681",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The dataset constructor requires a lookup table for class probabilities.\n",
    "class_prob_lookup = {\n",
    "    z['label']: z['prob']\n",
    "    for z in class_info.to_dict('records')\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d83eeccb-765f-4e54-8e6d-3dd96b7527f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded ../data/ne-laptop/models/model-101\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GeospatialTransformer(\n",
       "  (input_proj): Linear(in_features=422, out_features=128, bias=True)\n",
       "  (encoder): TransformerEncoder(\n",
       "    (layers): ModuleList(\n",
       "      (0-3): 4 x TransformerEncoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)\n",
       "        )\n",
       "        (linear1): Linear(in_features=128, out_features=512, bias=True)\n",
       "        (dropout): Dropout(p=0.2, inplace=False)\n",
       "        (linear2): Linear(in_features=512, out_features=128, bias=True)\n",
       "        (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0.2, inplace=False)\n",
       "        (dropout2): Dropout(p=0.2, inplace=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (output_head): Linear(in_features=128, out_features=22, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the model.\n",
    "model_fname = '%s/models/model-%s' % (roi_home, run_id)\n",
    "model = torch.load(model_fname, weights_only=False)\n",
    "print('loaded %s' % model_fname)\n",
    "\n",
    "model.to(device)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bfc366b6-585b-4a1f-8320-4a6a8933f5ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " ../data/ne-laptop/encodings/0731w-413n.pkl\n",
      "loaded 63 instances from ../data/ne-laptop/encodings/0731w-413n.pkl\n",
      "wrote ../data/ne-laptop/initials/0731w-413n.pkl\n",
      "\n",
      " ../data/ne-laptop/encodings/0731w-414n.pkl\n",
      "loaded 63 instances from ../data/ne-laptop/encodings/0731w-414n.pkl\n",
      "wrote ../data/ne-laptop/initials/0731w-414n.pkl\n",
      "\n",
      " ../data/ne-laptop/encodings/0731w-415n.pkl\n",
      "loaded 63 instances from ../data/ne-laptop/encodings/0731w-415n.pkl\n",
      "wrote ../data/ne-laptop/initials/0731w-415n.pkl\n",
      "\n",
      " ../data/ne-laptop/encodings/0732w-413n.pkl\n",
      "loaded 63 instances from ../data/ne-laptop/encodings/0732w-413n.pkl\n",
      "wrote ../data/ne-laptop/initials/0732w-413n.pkl\n",
      "\n",
      " ../data/ne-laptop/encodings/0732w-415n.pkl\n",
      "loaded 60 instances from ../data/ne-laptop/encodings/0732w-415n.pkl\n",
      "wrote ../data/ne-laptop/initials/0732w-415n.pkl\n",
      "\n",
      " ../data/ne-laptop/encodings/0732w-418n.pkl\n",
      "loaded 36 instances from ../data/ne-laptop/encodings/0732w-418n.pkl\n",
      "wrote ../data/ne-laptop/initials/0732w-418n.pkl\n",
      "\n",
      " ../data/ne-laptop/encodings/0732w-426n.pkl\n",
      "loaded 22 instances from ../data/ne-laptop/encodings/0732w-426n.pkl\n",
      "wrote ../data/ne-laptop/initials/0732w-426n.pkl\n",
      "\n",
      " ../data/ne-laptop/encodings/0732w-444n.pkl\n",
      "loaded 61 instances from ../data/ne-laptop/encodings/0732w-444n.pkl\n",
      "wrote ../data/ne-laptop/initials/0732w-444n.pkl\n",
      "\n",
      " ../data/ne-laptop/encodings/0732w-445n.pkl\n",
      "loaded 52 instances from ../data/ne-laptop/encodings/0732w-445n.pkl\n",
      "wrote ../data/ne-laptop/initials/0732w-445n.pkl\n",
      "\n",
      " ../data/ne-laptop/encodings/0733w-413n.pkl\n",
      "loaded 63 instances from ../data/ne-laptop/encodings/0733w-413n.pkl\n",
      "wrote ../data/ne-laptop/initials/0733w-413n.pkl\n",
      "\n",
      " ../data/ne-laptop/encodings/0733w-414n.pkl\n",
      "loaded 62 instances from ../data/ne-laptop/encodings/0733w-414n.pkl\n",
      "wrote ../data/ne-laptop/initials/0733w-414n.pkl\n",
      "\n",
      " ../data/ne-laptop/encodings/0733w-423n.pkl\n",
      "loaded 41 instances from ../data/ne-laptop/encodings/0733w-423n.pkl\n",
      "wrote ../data/ne-laptop/initials/0733w-423n.pkl\n",
      "\n",
      " ../data/ne-laptop/encodings/0733w-424n.pkl\n",
      "loaded 59 instances from ../data/ne-laptop/encodings/0733w-424n.pkl\n",
      "wrote ../data/ne-laptop/initials/0733w-424n.pkl\n",
      "\n",
      " ../data/ne-laptop/encodings/0733w-444n.pkl\n",
      "loaded 18 instances from ../data/ne-laptop/encodings/0733w-444n.pkl\n",
      "wrote ../data/ne-laptop/initials/0733w-444n.pkl\n",
      "\n",
      " ../data/ne-laptop/encodings/0733w-445n.pkl\n",
      "loaded 44 instances from ../data/ne-laptop/encodings/0733w-445n.pkl\n",
      "wrote ../data/ne-laptop/initials/0733w-445n.pkl\n",
      "\n",
      " ../data/ne-laptop/encodings/0734w-414n.pkl\n",
      "loaded 63 instances from ../data/ne-laptop/encodings/0734w-414n.pkl\n",
      "wrote ../data/ne-laptop/initials/0734w-414n.pkl\n",
      "\n",
      " ../data/ne-laptop/encodings/0735w-413n.pkl\n",
      "loaded 63 instances from ../data/ne-laptop/encodings/0735w-413n.pkl\n",
      "wrote ../data/ne-laptop/initials/0735w-413n.pkl\n",
      "\n",
      " ../data/ne-laptop/encodings/0735w-414n.pkl\n",
      "loaded 63 instances from ../data/ne-laptop/encodings/0735w-414n.pkl\n",
      "wrote ../data/ne-laptop/initials/0735w-414n.pkl\n",
      "\n",
      " ../data/ne-laptop/encodings/0735w-415n.pkl\n",
      "loaded 58 instances from ../data/ne-laptop/encodings/0735w-415n.pkl\n",
      "wrote ../data/ne-laptop/initials/0735w-415n.pkl\n",
      "\n",
      " ../data/ne-laptop/encodings/0735w-446n.pkl\n",
      "loaded 39 instances from ../data/ne-laptop/encodings/0735w-446n.pkl\n",
      "wrote ../data/ne-laptop/initials/0735w-446n.pkl\n"
     ]
    }
   ],
   "source": [
    "# Loop over encoded input files. For each one, define a dataset,\n",
    "# run it through the model, and generate an initial set of embeddings.\n",
    "for aoi_tag in aoi_tags:\n",
    "    \n",
    "    encoding_fname = '%s/encodings/%s.pkl' % (roi_home, aoi_tag)\n",
    "    print('\\n', encoding_fname)\n",
    "\n",
    "    # Define a dataset and datloader for this input file.\n",
    "    # Note that we set the batch size to 1. This effectively removes all\n",
    "    # padding, as the dataloader pads to the largest object\n",
    "    # in the batch. \n",
    "    dataset = VergeDataset([encoding_fname], n_classes, mask_fraction=0.0, class_prob=class_prob_lookup)\n",
    "    dataloader = DataLoader(\n",
    "        dataset,\n",
    "        batch_size=1,\n",
    "        shuffle=True,\n",
    "        collate_fn=verge_collate_fn,\n",
    "        drop_last=False\n",
    "    )\n",
    "\n",
    "    # Get embeddings for every tile in this AOI.\n",
    "    embeddings_for_this_aoi = []\n",
    "    for features, labels, attention_mask, idents in dataloader:\n",
    "        features = features.to(device)\n",
    "        attention_mask = attention_mask.to(device)\n",
    "        labels = labels.to(device)\n",
    "        embeddings = model.embed(features, attention_mask)\n",
    "        embeddings_for_this_aoi.append({\n",
    "            'aoi_tag': idents[0].split(':')[0],\n",
    "            'tile_tag': idents[0].split(':')[1],\n",
    "            'embedding': embeddings\n",
    "        })\n",
    "\n",
    "    # Save those.\n",
    "    ofname = '%s/initials/%s.pkl' % (roi_home, aoi_tag)\n",
    "    os.makedirs(os.path.dirname(ofname), exist_ok=True)\n",
    "    with open(ofname, 'wb') as dest:\n",
    "        pickle.dump(embeddings_for_this_aoi, dest)\n",
    "    print('wrote %s' % ofname)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9aeabc88-bf27-441b-849e-2079fa809c64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0735w-446n'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idents[0].split(':')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "68e33c4f-3db5-43f6-a7df-ae0ab5ff58ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Initialize training and validation datasets.\n",
    "# train_dataset = VergeDataset(train_fnames, n_classes, mask_fraction=0.0, class_prob=class_prob_lookup)\n",
    "# train_dataloader = DataLoader(\n",
    "#     train_dataset,\n",
    "#     batch_size=64, # Tune depending on GPU memory\n",
    "#     shuffle=True,\n",
    "#     collate_fn=verge_collate_fn,\n",
    "#     drop_last=False\n",
    "# )\n",
    "\n",
    "# val_dataset = VergeDataset(val_fnames, n_classes, mask_fraction=0.0, class_prob=class_prob_lookup)\n",
    "# val_dataloader = DataLoader(\n",
    "#     val_dataset,\n",
    "#     batch_size=64, # Tune depending on GPU memory\n",
    "#     shuffle=True,\n",
    "#     collate_fn=verge_collate_fn,\n",
    "#     drop_last=False\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cGkECEMi3ixw",
   "metadata": {
    "id": "cGkECEMi3ixw"
   },
   "outputs": [],
   "source": [
    "# val_dataset = VergeDataset(val_fnames, n_classes, mask_fraction=0.0, class_prob=class_prob_lookup)\n",
    "# val_dataloader = DataLoader(\n",
    "#     val_dataset,\n",
    "#     batch_size=64, # Tune depending on GPU memory\n",
    "#     shuffle=True,\n",
    "#     collate_fn=verge_collate_fn,\n",
    "#     drop_last=False\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "C6pnWfAV3ID3",
   "metadata": {
    "id": "C6pnWfAV3ID3"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c10079b1",
   "metadata": {
    "id": "c10079b1"
   },
   "source": [
    "## QA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41f79da7-133d-4f42-ab8e-77eb248cc382",
   "metadata": {
    "id": "41f79da7-133d-4f42-ab8e-77eb248cc382"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "A100",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
