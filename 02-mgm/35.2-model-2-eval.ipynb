{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e86b8916-bdd0-46e6-8195-8de0a4a06ab4",
   "metadata": {
    "id": "e86b8916-bdd0-46e6-8195-8de0a4a06ab4"
   },
   "source": [
    "### VERGE: Vector-mode Regional Geospatial Encoding\n",
    "# Model evaluation\n",
    "\n",
    "\n",
    "Elsewhere we trained a model to predict geospatial entity type from the encodings of the things\n",
    "in its vicinity. Here we run an evaluation.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8M2z1JqEbum-",
   "metadata": {
    "id": "8M2z1JqEbum-"
   },
   "source": [
    "## Colab setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "SDCVXcwwbuNz",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 19805,
     "status": "ok",
     "timestamp": 1751557398691,
     "user": {
      "displayName": "John Collins",
      "userId": "16643596247369517939"
     },
     "user_tz": 240
    },
    "id": "SDCVXcwwbuNz",
    "outputId": "f1891e38-1f8e-4808-ec27-825f1b5029e2"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "project_home = '/content/drive/MyDrive/Projects/verge'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "EJh-qkB0byEf",
   "metadata": {
    "id": "EJh-qkB0byEf"
   },
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b54d7995-33a4-44b6-a248-4d97c86ce57c",
   "metadata": {
    "executionInfo": {
     "elapsed": 4473,
     "status": "ok",
     "timestamp": 1751557403172,
     "user": {
      "displayName": "John Collins",
      "userId": "16643596247369517939"
     },
     "user_tz": 240
    },
    "id": "b54d7995-33a4-44b6-a248-4d97c86ce57c"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "import pickle\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.utils\n",
    "import torch.utils.data\n",
    "from torch.utils.data import DataLoader\n",
    "import copy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "445ca7e3-ead1-4ddd-b908-e3ecf2d2aef2",
   "metadata": {
    "id": "445ca7e3-ead1-4ddd-b908-e3ecf2d2aef2"
   },
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee168238-1ed3-44c8-af9b-c1907aadfab2",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 39,
     "status": "ok",
     "timestamp": 1751557403215,
     "user": {
      "displayName": "John Collins",
      "userId": "16643596247369517939"
     },
     "user_tz": 240
    },
    "id": "ee168238-1ed3-44c8-af9b-c1907aadfab2",
    "outputId": "cddec817-ecf5-4092-affd-baa65f246088"
   },
   "outputs": [],
   "source": [
    "# A unique identifier for this run. This will be a component of any\n",
    "# output file names.\n",
    "run_id = '003'\n",
    "\n",
    "# What type of device to train on.\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print('using device', device)\n",
    "\n",
    "# This is the dimension of the (square) AOIs. Set this to match what was used\n",
    "# when the tiles were created.\n",
    "aoi_size = 1000\n",
    "\n",
    "# This is the resolution of the MPP encoding.\n",
    "resolution = 50\n",
    "\n",
    "# This is how many elements there are in a geometric encoding. This is actually\n",
    "# implied by the MPP encoding resolution and the AOI size.\n",
    "geo_encoding_dim = 400\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae4c1f54-443b-4820-ae36-b00ed6d575d1",
   "metadata": {
    "id": "ae4c1f54-443b-4820-ae36-b00ed6d575d1"
   },
   "source": [
    "## Preliminaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d216238e-a075-4a1d-81cf-3269d8c82fb8",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1938,
     "status": "ok",
     "timestamp": 1751557405150,
     "user": {
      "displayName": "John Collins",
      "userId": "16643596247369517939"
     },
     "user_tz": 240
    },
    "id": "d216238e-a075-4a1d-81cf-3269d8c82fb8",
    "outputId": "6b0e3a0c-79c5-40bb-db0f-2e2ffe696dcf"
   },
   "outputs": [],
   "source": [
    "# Read the list of labels.\n",
    "fname = '%s/data/labels.csv' % project_home\n",
    "labels = pd.read_csv(fname)\n",
    "n_classes = len(labels)\n",
    "print('%d labels in this dataset' % n_classes)\n",
    "\n",
    "label_id_lookup = {\n",
    "    z['label']: z['id']\n",
    "    for z in labels.to_dict('records')\n",
    "}\n",
    "\n",
    "label_name_lookup = {\n",
    "    z['id']: z['label']\n",
    "    for z in labels.to_dict('records')\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "PGWG-XHKFLmq",
   "metadata": {
    "id": "PGWG-XHKFLmq"
   },
   "source": [
    "## Load data\n",
    "We determine which filed to read by loading the associated \"split\" file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d2cdcfd-701e-44e5-9565-840775cf6534",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 29431,
     "status": "ok",
     "timestamp": 1751557434582,
     "user": {
      "displayName": "John Collins",
      "userId": "16643596247369517939"
     },
     "user_tz": 240
    },
    "id": "8d2cdcfd-701e-44e5-9565-840775cf6534",
    "outputId": "e9b75d8e-27a5-4c87-97e7-4c55a94b0577"
   },
   "outputs": [],
   "source": [
    "splits_fname = '%s/splits/split-%s.csv' % (project_home, run_id)\n",
    "splits = pd.read_csv(splits_fname)\n",
    "val_fnames = splits[splits['type'] == 'val']['fname'].tolist()\n",
    "print('%d files with validation data' % len(val_fnames))\n",
    "\n",
    "# Read some data.\n",
    "val_tiles = []\n",
    "for fname in val_fnames:\n",
    "    print('reading', fname)\n",
    "    with open(fname, 'rb') as source:\n",
    "        val_tiles += pickle.load(source)\n",
    "\n",
    "print('%d validation instances' % len(val_tiles))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "575ef620-9a45-4215-8fdb-b9b35f3820dc",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 228,
     "status": "ok",
     "timestamp": 1751557434813,
     "user": {
      "displayName": "John Collins",
      "userId": "16643596247369517939"
     },
     "user_tz": 240
    },
    "id": "575ef620-9a45-4215-8fdb-b9b35f3820dc",
    "outputId": "0edc3cd7-7b94-4b34-be1f-1c873ec45a92"
   },
   "outputs": [],
   "source": [
    "# This class wraps a list of input tile data as a pytorch dataset.\n",
    "# The \"getitem\" method here parses apart the true labels and the encodings,\n",
    "# and applies random masking to the encoding.\n",
    "\n",
    "class VergeDataset(torch.utils.data.Dataset):\n",
    "\n",
    "    def __init__(self, data_list, n_classes, mask_fraction):\n",
    "        self.data = data_list\n",
    "        self.n_classes = n_classes\n",
    "        self.mask_fraction = mask_fraction\n",
    "        self.encoding_dim = data_list[0].shape[1] - self.n_classes\n",
    "        # print('encoding_dim', self.encoding_dim)\n",
    "        # print('n_classes', self.n_classes)\n",
    "\n",
    "        # When accessing any item, we will also be sampling from its available classes.\n",
    "        # But this dataset has a big class imbalance, so we will sample according\n",
    "        # to inverse probability. Here we compute the probability distribution of classes.\n",
    "        self.class_prob = {z: 0.0 for z in range(self.n_classes)}\n",
    "        n = 0.0\n",
    "        for d in data_list:\n",
    "            true_labels_onehot = d[:, :self.n_classes]\n",
    "            true_labels = np.argmax(true_labels_onehot, axis=1)\n",
    "            for label in true_labels:\n",
    "                self.class_prob[label] += 1.0\n",
    "            n += len(true_labels)\n",
    "        for label in self.class_prob:\n",
    "            self.class_prob[label] /= n\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "        features = self.data[idx]\n",
    "        encodings = features[:, self.n_classes:]\n",
    "        true_labels_onehot = features[:, :self.n_classes]\n",
    "        true_labels = np.argmax(true_labels_onehot, axis=1)\n",
    "        n_entities = features.shape[0]\n",
    "\n",
    "        # Sample eneite to mask. This weights the sampling by the relative\n",
    "        # frequency of different classes in the dataset -- i.e. it addresses\n",
    "        # class imbalance.\n",
    "        weights = []\n",
    "        for label in true_labels:\n",
    "            prob = self.class_prob[label]\n",
    "            weights.append(1.0 / (prob + 0.001))\n",
    "        weights = np.array(weights)\n",
    "        weights = weights / np.sum(weights)\n",
    "        sample_size = int(np.ceil(self.mask_fraction * n_entities))\n",
    "        mask_indices = np.random.choice(n_entities, size=sample_size, replace=True, p=weights)\n",
    "\n",
    "        # The old way: no weighting in selection of masked entities.\n",
    "        # mask = np.random.rand(n_entities) < self.mask_fraction\n",
    "        # mask_indices = np.where(mask)[0]\n",
    "        # print('mask_indices', mask_indices)\n",
    "\n",
    "        # In the feature array, labels are one-hot vectors that get concatenated\n",
    "        # with the geometric encodings. To \"mask\" those labels, we replace the\n",
    "        # one-hot vector with a zero-hot vector.\n",
    "        mask_vector = np.zeros(self.n_classes)\n",
    "        masked_labels_onehot = copy.copy(true_labels_onehot)\n",
    "        for i in mask_indices:\n",
    "            masked_labels_onehot[i] = mask_vector\n",
    "            # print('replaced one-hot vectdor for row %d' % i)\n",
    "\n",
    "        # Re-concatenate the masked labels with the geometric encodings.\n",
    "        masked_labels_onehot_tensor = torch.tensor(masked_labels_onehot, dtype=torch.float32)\n",
    "        encodings_tensor = torch.tensor(encodings, dtype=torch.float32)\n",
    "        masked_features = torch.cat(\n",
    "            [masked_labels_onehot_tensor, encodings_tensor], dim=1\n",
    "        )\n",
    "\n",
    "        # During model training below, we will be using the \"CrossEntropyLoss\" function,\n",
    "        # which has a built-in capability to ignore elements thatwe don't care about,\n",
    "        # which in this case is any element that is NOT masked. To get it to work,\n",
    "        # we need to pack an \"ignore\" token into any label slot that is not masked.\n",
    "        # Pytorch's standard value for that token is -100. Or more specifically\n",
    "        # we start with all \"ignore\" tokens and just replace the ones that we do\n",
    "        # care about with the appropriate value.\n",
    "        labels = torch.full(true_labels.shape, -100, dtype=torch.long)\n",
    "        for i in mask_indices:\n",
    "            labels[i] = true_labels[i]\n",
    "            # print('set true label for element %d to %d' % (i, true_labels[i]))\n",
    "\n",
    "        # Shuffle the features and labels.\n",
    "        perm = torch.randperm(masked_features.shape[0])\n",
    "        masked_features = masked_features[perm]\n",
    "        labels = labels[perm]\n",
    "\n",
    "        return (masked_features, labels)\n",
    "\n",
    "dataset = VergeDataset(val_tiles, n_classes, mask_fraction=0.2)\n",
    "features, labels = dataset[0]\n",
    "print('features.shape', features.shape)\n",
    "print('labels.shape', labels.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11cd86c9-551f-42f7-a303-c8f99af4c9e1",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 63,
     "status": "ok",
     "timestamp": 1751557434882,
     "user": {
      "displayName": "John Collins",
      "userId": "16643596247369517939"
     },
     "user_tz": 240
    },
    "id": "11cd86c9-551f-42f7-a303-c8f99af4c9e1",
    "outputId": "71416e1d-22ca-407b-fde8-4c5bc9d20738"
   },
   "outputs": [],
   "source": [
    "# Define the function that puts together a batch. The main thing we are handling here\n",
    "# is padding. We make all arrays have a size equal to the largest one in the batch,\n",
    "# with excess space filled with padding tokens.\n",
    "def collate_fn(batch):\n",
    "\n",
    "    features, labels = zip(*batch)\n",
    "    max_len = max(x.shape[0] for x in features)\n",
    "    batch_size = len(features)\n",
    "    feature_dim = features[0].shape[1]\n",
    "\n",
    "    padded_features = torch.zeros(batch_size, max_len, feature_dim)\n",
    "    padded_labels = torch.full((batch_size, max_len), -100, dtype=torch.long)  # -100 is the \"ignore\" value\n",
    "    attention_mask = torch.zeros(batch_size, max_len, dtype=torch.bool)\n",
    "\n",
    "    for i in range(batch_size):\n",
    "        n = features[i].shape[0]\n",
    "        padded_features[i, :n] = features[i]\n",
    "        padded_labels[i, :n] = labels[i]\n",
    "        attention_mask[i, :n] = 1\n",
    "\n",
    "    return padded_features, padded_labels, attention_mask\n",
    "\n",
    "\n",
    "# Test that.\n",
    "dataset = VergeDataset(val_tiles, n_classes, mask_fraction=0.15)\n",
    "batch = [dataset[k] for k in [0, 12, 17, 23]]\n",
    "batch_features, batch_labels, batch_attention_mask = collate_fn(batch)\n",
    "print('batch_features.shape', batch_features.shape)\n",
    "print('batch_labels.shape', batch_labels.shape)\n",
    "print('batch_attention_mask.shape', batch_attention_mask.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "419b685c-980f-42d5-8d7a-a195b3f8705e",
   "metadata": {
    "id": "419b685c-980f-42d5-8d7a-a195b3f8705e"
   },
   "source": [
    "## Model definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "075bfddc-5d69-4797-866d-a300b20fb006",
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1751557434888,
     "user": {
      "displayName": "John Collins",
      "userId": "16643596247369517939"
     },
     "user_tz": 240
    },
    "id": "075bfddc-5d69-4797-866d-a300b20fb006"
   },
   "outputs": [],
   "source": [
    "class GeospatialTransformer(nn.Module):\n",
    "\n",
    "\n",
    "    def __init__(self, feature_dim, model_dim, num_heads, num_layers, num_classes, dropout):\n",
    "        super().__init__()\n",
    "\n",
    "        self.input_proj = nn.Linear(feature_dim, model_dim)\n",
    "\n",
    "        encoder_layer = nn.TransformerEncoderLayer(\n",
    "            d_model=model_dim,\n",
    "            nhead=num_heads,\n",
    "            dim_feedforward=4 * model_dim,\n",
    "            dropout=dropout,\n",
    "            batch_first=True\n",
    "        )\n",
    "        self.encoder = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)\n",
    "        self.output_head = nn.Linear(model_dim, num_classes)\n",
    "\n",
    "\n",
    "    def forward(self, x, attention_mask):\n",
    "        \"\"\"\n",
    "        x: Tensor of shape [batch_size, n_entities, encoding_dim]\n",
    "        attention_mask: Tensor of shape [batch_size, n_entities], with 1 for valid, 0 for padding\n",
    "        \"\"\"\n",
    "        # print('input', x.shape)\n",
    "\n",
    "        x = self.input_proj(x)\n",
    "        # print('projected', x.shape)\n",
    "\n",
    "        # Transformer expects padding mask: True for PAD tokens\n",
    "        pad_mask = (attention_mask == 0)\n",
    "        x = self.encoder(x, src_key_padding_mask=pad_mask)\n",
    "        # print('transformed', x.shape)\n",
    "\n",
    "        logits = self.output_head(x)\n",
    "        # print('logits', logits.shape)\n",
    "\n",
    "        return logits\n",
    "\n",
    "\n",
    "    def embed(self, x, attention_mask):\n",
    "        \"\"\"\n",
    "        Returns an embedding for the input features\n",
    "        \"\"\"\n",
    "        x = self.input_proj(x)\n",
    "        pad_mask = (attention_mask == 0)\n",
    "        x = self.encoder(x, src_key_padding_mask=pad_mask)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daedea23-2671-49d1-85a8-ec5c557a8ea2",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1751557434920,
     "user": {
      "displayName": "John Collins",
      "userId": "16643596247369517939"
     },
     "user_tz": 240
    },
    "id": "daedea23-2671-49d1-85a8-ec5c557a8ea2",
    "outputId": "4c33599f-328a-43d2-e4e5-aadffe406cfe"
   },
   "outputs": [],
   "source": [
    "model = GeospatialTransformer(\n",
    "    feature_dim = geo_encoding_dim + n_classes,\n",
    "    model_dim=128,\n",
    "    num_heads=4,\n",
    "    num_layers=4,\n",
    "    num_classes=n_classes,\n",
    "    dropout=0.2\n",
    ")\n",
    "n_param = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print('%d trainable parameters in model' % n_param)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa310216-b622-42e2-a551-322943108993",
   "metadata": {
    "id": "fa310216-b622-42e2-a551-322943108993"
   },
   "source": [
    "## Prep model and data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5116f8b4-2ad4-47ad-8c3d-7128e93456a0",
   "metadata": {
    "executionInfo": {
     "elapsed": 80,
     "status": "ok",
     "timestamp": 1751557435003,
     "user": {
      "displayName": "John Collins",
      "userId": "16643596247369517939"
     },
     "user_tz": 240
    },
    "id": "5116f8b4-2ad4-47ad-8c3d-7128e93456a0"
   },
   "outputs": [],
   "source": [
    "# Initialize validation datases.\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "val_dataset = VergeDataset(val_tiles, n_classes, mask_fraction=0.15)\n",
    "val_dataloader = DataLoader(\n",
    "    dataset,\n",
    "    batch_size=16, # Tune depending on GPU memory\n",
    "    shuffle=True,\n",
    "    collate_fn=collate_fn,\n",
    "    drop_last=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "C6pnWfAV3ID3",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 930,
     "status": "ok",
     "timestamp": 1751557435936,
     "user": {
      "displayName": "John Collins",
      "userId": "16643596247369517939"
     },
     "user_tz": 240
    },
    "id": "C6pnWfAV3ID3",
    "outputId": "403168a4-c7c7-479e-f054-1a54e1fc87aa"
   },
   "outputs": [],
   "source": [
    "# Load the model.\n",
    "model_fname = '%s/models/model-%s' % (project_home, run_id)\n",
    "model = torch.load(model_fname, weights_only=False)\n",
    "print('loaded %s' % model_fname)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c10079b1",
   "metadata": {
    "id": "c10079b1"
   },
   "source": [
    "## Validation Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fb80ef4",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 10415,
     "status": "ok",
     "timestamp": 1751557446337,
     "user": {
      "displayName": "John Collins",
      "userId": "16643596247369517939"
     },
     "user_tz": 240
    },
    "id": "9fb80ef4",
    "outputId": "ff11428f-7e73-4e37-fbac-0d1436c0256a"
   },
   "outputs": [],
   "source": [
    "# Process the validation dataset, getting the class probability predictions\n",
    "# for every instance.\n",
    "model.to(device)\n",
    "cases = []\n",
    "\n",
    "model.eval()\n",
    "for features, labels, attention_mask in val_dataloader:\n",
    "\n",
    "    features = features.to(device)\n",
    "    attention_mask = attention_mask.to(device)\n",
    "    labels = labels.to(device)\n",
    "\n",
    "    logits = model(features, attention_mask)\n",
    "\n",
    "    batch_size = logits.shape[0]\n",
    "    for i in range(batch_size):\n",
    "        case_logits = logits[i]\n",
    "        case_probs = torch.softmax(case_logits, dim=1)\n",
    "        case_labels = labels[i]\n",
    "        entity_count = len(case_labels)\n",
    "        for k in range(entity_count):\n",
    "            if case_labels[k].item() >= 0: # Skips the \"-100\" labels.\n",
    "                cases.append({\n",
    "                    'true_label': case_labels[k].item(),\n",
    "                    'probs': torch.Tensor.cpu(case_probs[k, :]).detach().numpy()\n",
    "                })\n",
    "    # if len(cases) >= 1000:\n",
    "    #     break\n",
    "\n",
    "print('compiled prediction probabilities for %d validation instances' % len(cases))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd2752ef",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 607
    },
    "executionInfo": {
     "elapsed": 646,
     "status": "ok",
     "timestamp": 1751557446981,
     "user": {
      "displayName": "John Collins",
      "userId": "16643596247369517939"
     },
     "user_tz": 240
    },
    "id": "dd2752ef",
    "outputId": "10fa66d9-8d2e-4e0c-9130-21f238af1d7b"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict\n",
    "\n",
    "class_count = max(d[\"true_label\"] for d in cases) + 1\n",
    "probs_by_class = defaultdict(list)\n",
    "\n",
    "for d in cases:\n",
    "    label = d[\"true_label\"]\n",
    "    probs = np.array(d[\"probs\"])\n",
    "    probs_by_class[label].append(probs)\n",
    "\n",
    "# For each true class, compute the mean probability vector\n",
    "mean_probs = []\n",
    "for t in range(class_count):\n",
    "    if probs_by_class[t]:\n",
    "        mean = np.stack(probs_by_class[t]).mean(axis=0)\n",
    "    else:\n",
    "        mean = np.zeros(class_count)  # if no samples for this class\n",
    "    mean_probs.append(mean)\n",
    "\n",
    "# Convert to 2D array: [true_class, predicted_class]\n",
    "matrix = np.stack(mean_probs)  # shape [C, C]\n",
    "\n",
    "# Plot heatmap\n",
    "fig, ax = plt.subplots(figsize=(9, 6))\n",
    "im = ax.imshow(matrix, cmap='viridis', aspect='auto')\n",
    "\n",
    "plt.colorbar(im, ax=ax, label='Avg Predicted Probability')\n",
    "ax.set_title(\"Mean Predicted Probabilities by True Class\")\n",
    "ax.set_xlabel(\"Predicted Class\")\n",
    "ax.set_ylabel(\"True Class\")\n",
    "ax.set_xticks(range(class_count))\n",
    "ax.set_yticks(range(class_count))\n",
    "ax.set_yticklabels(['%s [%d]' % (label_name_lookup[i], i) for i in range(class_count)])\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25618be6",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 737
    },
    "executionInfo": {
     "elapsed": 347,
     "status": "ok",
     "timestamp": 1751557447331,
     "user": {
      "displayName": "John Collins",
      "userId": "16643596247369517939"
     },
     "user_tz": 240
    },
    "id": "25618be6",
    "outputId": "47339d2e-5f51-49a9-fe65-9032e3217618"
   },
   "outputs": [],
   "source": [
    "# Comfusion matrix.\n",
    "\n",
    "class_count = max(d[\"true_label\"] for d in cases) + 1\n",
    "print(class_count)\n",
    "cmat = np.zeros((class_count, class_count))\n",
    "\n",
    "for d in cases:\n",
    "    true_label = d[\"true_label\"]\n",
    "    pred_label = np.argmax(d[\"probs\"])\n",
    "    cmat[true_label, pred_label] += 1\n",
    "\n",
    "cmat = np.sqrt(cmat)\n",
    "\n",
    "# Plot heatmap\n",
    "fig, ax = plt.subplots(figsize=(12, 8))\n",
    "im = ax.imshow(cmat, cmap='viridis', aspect='auto')\n",
    "\n",
    "plt.colorbar(im, ax=ax, label='Number Of Cases')\n",
    "ax.set_title(\"Confusion Matrix\")\n",
    "ax.set_xlabel(\"Predicted Class\")\n",
    "ax.set_ylabel(\"True Class\")\n",
    "ax.set_xticks(range(class_count))\n",
    "ax.set_yticks(range(class_count))\n",
    "ax.set_yticklabels([label_name_lookup[i] for i in range(class_count)])\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "QkwGn1oASpdV",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 696,
     "status": "ok",
     "timestamp": 1751557448021,
     "user": {
      "displayName": "John Collins",
      "userId": "16643596247369517939"
     },
     "user_tz": 240
    },
    "id": "QkwGn1oASpdV",
    "outputId": "44038abf-0e2d-49fa-c6d9-c67e8257e753"
   },
   "outputs": [],
   "source": [
    "# Accuracy stats\n",
    "\n",
    "from sklearn.metrics import top_k_accuracy_score, f1_score\n",
    "\n",
    "y_true = np.array([d[\"true_label\"] for d in cases])\n",
    "y_pred = np.array([np.argmax(d[\"probs\"]) for d in cases])\n",
    "y_prob = np.vstack([d[\"probs\"] for d in cases])\n",
    "\n",
    "print('top-1 accuracy: %.4f' % top_k_accuracy_score(y_true, y_prob, k=1))\n",
    "print('top-2 accuracy: %.4f' % top_k_accuracy_score(y_true, y_prob, k=2))\n",
    "print('top-3 accuracy: %.4f' % top_k_accuracy_score(y_true, y_prob, k=3))\n",
    "print('top-4 accuracy: %.4f' % top_k_accuracy_score(y_true, y_prob, k=4))\n",
    "print('top-5 accuracy: %.4f' % top_k_accuracy_score(y_true, y_prob, k=5))\n",
    "print('f1 score: %.4f' % f1_score(y_true, y_pred, average='macro'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "G6ijwhjy6XZP",
   "metadata": {
    "id": "G6ijwhjy6XZP"
   },
   "source": [
    "## Check consistency with respect to randomization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "A7NznUeG7vCQ",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 41,
     "status": "ok",
     "timestamp": 1751557448066,
     "user": {
      "displayName": "John Collins",
      "userId": "16643596247369517939"
     },
     "user_tz": 240
    },
    "id": "A7NznUeG7vCQ",
    "outputId": "1d5d63b0-758c-4e75-c23a-ace34dd70a4e"
   },
   "outputs": [],
   "source": [
    "# Get a \"batch\" consisting of one instance.\n",
    "dataset = VergeDataset(val_tiles, n_classes, mask_fraction=0.15)\n",
    "batch = [dataset[k] for k in [3]]\n",
    "batch_features, batch_labels, batch_attention_mask = collate_fn(batch)\n",
    "batch_labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "RDFrypwa8fam",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 41,
     "status": "ok",
     "timestamp": 1751557448111,
     "user": {
      "displayName": "John Collins",
      "userId": "16643596247369517939"
     },
     "user_tz": 240
    },
    "id": "RDFrypwa8fam",
    "outputId": "b1024291-f55d-44cf-86fc-218d69903121"
   },
   "outputs": [],
   "source": [
    "# Get the logits for that batch.\n",
    "model.to(device)\n",
    "batch_features = batch_features.to(device)\n",
    "batch_attention_mask = batch_attention_mask.to(device)\n",
    "logits = model(batch_features, batch_attention_mask)\n",
    "print(logits.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "noz6mCxM9teW",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 43,
     "status": "ok",
     "timestamp": 1751557448157,
     "user": {
      "displayName": "John Collins",
      "userId": "16643596247369517939"
     },
     "user_tz": 240
    },
    "id": "noz6mCxM9teW",
    "outputId": "82f0b638-5076-4613-fb99-19afc2f1de62"
   },
   "outputs": [],
   "source": [
    "# Get a random permutation to be applied to the rows of the batch.\n",
    "# Permute every row except the first -- we will use that as a reference.\n",
    "perm = torch.concat((\n",
    "    torch.tensor([0]),\n",
    "    torch.randperm(batch_features.shape[1] - 1) + 1\n",
    "))\n",
    "print(perm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "_1CSwU3m9-Uy",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 60,
     "status": "ok",
     "timestamp": 1751557448214,
     "user": {
      "displayName": "John Collins",
      "userId": "16643596247369517939"
     },
     "user_tz": 240
    },
    "id": "_1CSwU3m9-Uy",
    "outputId": "b78ad7ac-91bf-4b5d-f993-03e35ddb83a6"
   },
   "outputs": [],
   "source": [
    "# Apply the permutation to the features and re-run the model.\n",
    "permuted_features = batch_features.clone()\n",
    "permuted_features = permuted_features[:, perm]\n",
    "permuted_features.to(device)\n",
    "permuted_logits = model(permuted_features, batch_attention_mask)\n",
    "print(permuted_logits.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "SqSCEgfW-DbS",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 250,
     "status": "ok",
     "timestamp": 1751557448453,
     "user": {
      "displayName": "John Collins",
      "userId": "16643596247369517939"
     },
     "user_tz": 240
    },
    "id": "SqSCEgfW-DbS",
    "outputId": "0a7700ea-ec2b-48bd-8df5-161e33fd0297"
   },
   "outputs": [],
   "source": [
    "# Extract the corresponding logits from the original and permuted result.\n",
    "a_index = 0\n",
    "b_index = torch.where(perm == a_index)[0][0].item()\n",
    "print(a_index, b_index)\n",
    "a = logits[0, a_index]\n",
    "b = permuted_logits[0, b_index]\n",
    "print(a)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mWDemHx2-jwe",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 542
    },
    "executionInfo": {
     "elapsed": 511,
     "status": "ok",
     "timestamp": 1751557448960,
     "user": {
      "displayName": "John Collins",
      "userId": "16643596247369517939"
     },
     "user_tz": 240
    },
    "id": "mWDemHx2-jwe",
    "outputId": "8c14cedb-97da-49ef-a1b7-cec2eef41e67"
   },
   "outputs": [],
   "source": [
    "import plotly\n",
    "from plotly.subplots import make_subplots\n",
    "from plotly.graph_objects import Scatter\n",
    "\n",
    "aa = torch.Tensor.cpu(a).detach().numpy()\n",
    "bb = torch.Tensor.cpu(b).detach().numpy()\n",
    "\n",
    "fig = make_subplots(rows=1, cols=1)\n",
    "n = aa.shape[0]\n",
    "xx = np.arange(n)\n",
    "\n",
    "trace = Scatter(x=xx, y=aa, name='a', mode='markers+lines')\n",
    "fig.add_trace(trace, row=1, col=1)\n",
    "\n",
    "trace = Scatter(x=xx, y=bb, name='b', mode='markers+lines')\n",
    "fig.add_trace(trace, row=1, col=1)\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hnABe4I8zNOx",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1751557448965,
     "user": {
      "displayName": "John Collins",
      "userId": "16643596247369517939"
     },
     "user_tz": 240
    },
    "id": "hnABe4I8zNOx",
    "outputId": "e1b8ab63-5ac3-402c-9599-cc10455ea748"
   },
   "outputs": [],
   "source": [
    "batch_features[0, a_index, :] - permuted_features[0, b_index, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "xdUrSvIbMDD6",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 144,
     "status": "ok",
     "timestamp": 1751558443490,
     "user": {
      "displayName": "John Collins",
      "userId": "16643596247369517939"
     },
     "user_tz": 240
    },
    "id": "xdUrSvIbMDD6",
    "outputId": "5582b12d-eb56-499b-b196-53b5914d2749"
   },
   "outputs": [],
   "source": [
    "# Accuracy stats\n",
    "\n",
    "from sklearn.metrics import top_k_accuracy_score, f1_score\n",
    "\n",
    "y_true = np.array([d[\"true_label\"] for d in cases])\n",
    "y_pred = np.array([np.argmax(d[\"probs\"]) for d in cases])\n",
    "y_prob = np.vstack([d[\"probs\"] for d in cases])\n",
    "\n",
    "print('top-1 accuracy: %.4f' % top_k_accuracy_score(y_true, y_prob, k=1))\n",
    "print('top-2 accuracy: %.4f' % top_k_accuracy_score(y_true, y_prob, k=2))\n",
    "print('top-3 accuracy: %.4f' % top_k_accuracy_score(y_true, y_prob, k=3))\n",
    "print('top-4 accuracy: %.4f' % top_k_accuracy_score(y_true, y_prob, k=4))\n",
    "print('top-5 accuracy: %.4f' % top_k_accuracy_score(y_true, y_prob, k=5))\n",
    "print('f1 score: %.4f' % f1_score(y_true, y_pred, average='macro'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "RKBB47lHO7Vr",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1751557448971,
     "user": {
      "displayName": "John Collins",
      "userId": "16643596247369517939"
     },
     "user_tz": 240
    },
    "id": "RKBB47lHO7Vr",
    "outputId": "b59b11e5-0281-483e-d3dd-55180fcbeb58"
   },
   "outputs": [],
   "source": [
    "x = batch_features\n",
    "x_perm = x.clone()\n",
    "x_perm[:, [0, 1], :] = x_perm[:, [1, 0], :]  # Swap two entities in each sample\n",
    "logits_orig = model(x, batch_attention_mask)\n",
    "logits_perm = model(x_perm, batch_attention_mask)\n",
    "\n",
    "print((logits_orig - logits_perm).abs().max())  # Should be > 0 for non-invariant models\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
