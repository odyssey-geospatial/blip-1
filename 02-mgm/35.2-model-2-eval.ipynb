{"cells":[{"cell_type":"markdown","id":"e86b8916-bdd0-46e6-8195-8de0a4a06ab4","metadata":{"id":"e86b8916-bdd0-46e6-8195-8de0a4a06ab4"},"source":["### VERGE: Vector-Mode Regional Geospatial Encoding\n","# Model evaluation\n","\n","\n","Elsewhere we trained a model to predict geospatial entity type from the encodings of the things\n","in its vicinity. Here we run an evaluation.\n"]},{"cell_type":"markdown","id":"8M2z1JqEbum-","metadata":{"id":"8M2z1JqEbum-"},"source":["## Processing Setup"]},{"cell_type":"code","execution_count":null,"id":"SDCVXcwwbuNz","metadata":{"id":"SDCVXcwwbuNz"},"outputs":[],"source":["# Google colab setup\n","import os\n","from google.colab import drive\n","drive.mount('/content/drive')\n","project_home = '/content/drive/MyDrive/Projects/verge'\n","os.chdir(project_home)"]},{"cell_type":"code","source":["!pip install geo_encodings"],"metadata":{"id":"jfRkhxK615Hn"},"id":"jfRkhxK615Hn","execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Local processing setup\n","# project_home = '..'"],"metadata":{"id":"i_mx-hmv1fmE"},"id":"i_mx-hmv1fmE","execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Source"],"metadata":{"id":"L4cSLLSy1jCL"},"id":"L4cSLLSy1jCL"},{"cell_type":"code","execution_count":null,"id":"faeed93f-aa96-4f8b-8865-507f58adf0b3","metadata":{"id":"faeed93f-aa96-4f8b-8865-507f58adf0b3"},"outputs":[],"source":["# The name of the ROI to use.\n","roi_name = 'newengland'\n","\n","# The name of the general-purpose data directory.\n","data_home = '%s/data' % (project_home)\n","\n","# The name of the ROI-specific data directory.\n","roi_home = '%s/data/%s' % (project_home, roi_name)\n"]},{"cell_type":"markdown","id":"EJh-qkB0byEf","metadata":{"id":"EJh-qkB0byEf"},"source":["## Setup"]},{"cell_type":"code","execution_count":null,"id":"b54d7995-33a4-44b6-a248-4d97c86ce57c","metadata":{"id":"b54d7995-33a4-44b6-a248-4d97c86ce57c"},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","import glob\n","import pickle\n","import os\n","import torch\n","import torch.nn as nn\n","import torch.utils\n","import torch.utils.data\n","from torch.utils.data import DataLoader\n","import copy\n","import json\n","from geo_encodings import MPPEncoder\n","\n","import sys\n","sys.path.append(project_home)\n","from utils.geo_transformer_mem import VergeDataset, verge_collate_fn, GeospatialTransformer\n"]},{"cell_type":"markdown","id":"445ca7e3-ead1-4ddd-b908-e3ecf2d2aef2","metadata":{"id":"445ca7e3-ead1-4ddd-b908-e3ecf2d2aef2"},"source":["## Parameters"]},{"cell_type":"code","execution_count":null,"id":"12061fe8-4f75-48bb-9eb3-06216f7b8e74","metadata":{"id":"12061fe8-4f75-48bb-9eb3-06216f7b8e74"},"outputs":[],"source":["# Read the ROI definition.\n","fname = '%s/roi.json' % roi_home\n","with open(fname) as source:\n","    roi = json.load(source)\n","\n","tile_size = roi['tile_size']\n","encoding_resolution = roi['encoding_resolution']\n","\n","# We need the dimension of the encoding.\n","encoder = MPPEncoder(\n","    region=[0, 0, tile_size, tile_size],\n","    resolution=encoding_resolution,\n","    center=True\n",")\n","geo_encoding_dim = len(encoder)\n","print('%d elements in encodings' % geo_encoding_dim)\n"]},{"cell_type":"code","source":["roi"],"metadata":{"id":"F0Sqaom82fwW"},"id":"F0Sqaom82fwW","execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"id":"ee168238-1ed3-44c8-af9b-c1907aadfab2","metadata":{"id":"ee168238-1ed3-44c8-af9b-c1907aadfab2"},"outputs":[],"source":["run_id = '010'\n","\n","# What type of device to train on.\n","device = 'cuda' if torch.cuda.is_available() else 'cpu'\n","print('using device', device)"]},{"cell_type":"markdown","id":"ae4c1f54-443b-4820-ae36-b00ed6d575d1","metadata":{"id":"ae4c1f54-443b-4820-ae36-b00ed6d575d1"},"source":["## Preliminaries"]},{"cell_type":"code","execution_count":null,"id":"d216238e-a075-4a1d-81cf-3269d8c82fb8","metadata":{"id":"d216238e-a075-4a1d-81cf-3269d8c82fb8"},"outputs":[],"source":["# Read the list of labels.\n","fname = '%s/labels.csv' % data_home\n","labels = pd.read_csv(fname)\n","n_classes = len(labels)\n","print('%d labels in this dataset' % n_classes)\n","\n","label_id_lookup = {\n","    z['label']: z['id']\n","    for z in labels.to_dict('records')\n","}\n","\n","label_name_lookup = {\n","    z['id']: z['label']\n","    for z in labels.to_dict('records')\n","}"]},{"cell_type":"code","source":["# Read the file that gives class probabilities.\n","fname = '%s/class_info.csv' % roi_home\n","class_info = pd.read_csv(fname)\n","print('%d class info records' % len(class_info))"],"metadata":{"id":"d86rIhLz3w72"},"id":"d86rIhLz3w72","execution_count":null,"outputs":[]},{"cell_type":"markdown","id":"PGWG-XHKFLmq","metadata":{"id":"PGWG-XHKFLmq"},"source":["## Load data\n","We determine which filed to read by loading the associated \"split\" file."]},{"cell_type":"code","execution_count":null,"id":"8d2cdcfd-701e-44e5-9565-840775cf6534","metadata":{"id":"8d2cdcfd-701e-44e5-9565-840775cf6534"},"outputs":[],"source":["splits_fname = '%s/splits-%s.csv' % (roi_home, run_id)\n","splits = pd.read_csv(splits_fname)\n","val_fnames = splits[splits['split'] == 'val']['aoi'].tolist()\n","# val_fnames = splits[splits['type'] == 'train']['fname'].tolist()\n","print('%d files with validation data' % len(val_fnames))\n","\n","# Read some data.\n","val_tiles = []\n","for fname in val_fnames[:3]:\n","    print('reading', fname)\n","    with open(fname, 'rb') as source:\n","        val_tiles += pickle.load(source)\n","\n","print('%d validation tiles' % len(val_tiles))"]},{"cell_type":"markdown","id":"fa310216-b622-42e2-a551-322943108993","metadata":{"id":"fa310216-b622-42e2-a551-322943108993"},"source":["## Prep model and data"]},{"cell_type":"code","source":["# The dataset constructor requires a lookup table for class probabilities.\n","class_prob_lookup = {\n","    z['label']: z['prob']\n","    for z in class_info.to_dict('records')\n","}\n","\n","val_dataset = VergeDataset(val_fnames, n_classes, mask_fraction=0.15, class_prob=class_prob_lookup)\n","val_dataloader = DataLoader(\n","    val_dataset,\n","    batch_size=64, # Tune depending on GPU memory\n","    shuffle=True,\n","    collate_fn=verge_collate_fn,\n","    drop_last=False\n",")"],"metadata":{"id":"cGkECEMi3ixw"},"id":"cGkECEMi3ixw","execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"id":"C6pnWfAV3ID3","metadata":{"id":"C6pnWfAV3ID3"},"outputs":[],"source":["# Load the model.\n","model_fname = '%s/model-%s' % (roi_home, run_id)\n","model = torch.load(model_fname, weights_only=False)\n","print('loaded %s' % model_fname)"]},{"cell_type":"markdown","id":"c10079b1","metadata":{"id":"c10079b1"},"source":["## Validation Visualization"]},{"cell_type":"code","execution_count":null,"id":"9fb80ef4","metadata":{"id":"9fb80ef4"},"outputs":[],"source":["# Process the validation dataset, getting the class probability predictions\n","# for every instance.\n","model.to(device)\n","cases = []\n","\n","model.eval()\n","for features, labels, attention_mask in val_dataloader:\n","\n","    features = features.to(device)\n","    attention_mask = attention_mask.to(device)\n","    labels = labels.to(device)\n","    logits = model(features, attention_mask)\n","    batch_size = logits.shape[0]\n","    for i in range(batch_size):\n","        case_logits = logits[i]\n","        case_probs = torch.softmax(case_logits, dim=1)\n","        case_labels = labels[i]\n","        entity_count = len(case_labels)\n","        for k in range(entity_count):\n","            if case_labels[k].item() >= 0: # Skips the \"-100\" labels.\n","                cases.append({\n","                    'true_label': case_labels[k].item(),\n","                    'probs': torch.Tensor.cpu(case_probs[k, :]).detach().numpy()\n","                })\n","\n","print('compiled prediction probabilities for %d validation instances' % len(cases))"]},{"cell_type":"code","execution_count":null,"id":"dd2752ef","metadata":{"id":"dd2752ef"},"outputs":[],"source":["import numpy as np\n","import matplotlib.pyplot as plt\n","from collections import defaultdict\n","\n","class_count = max(d[\"true_label\"] for d in cases) + 1\n","probs_by_class = defaultdict(list)\n","\n","for d in cases:\n","    label = d[\"true_label\"]\n","    probs = np.array(d[\"probs\"])\n","    probs_by_class[label].append(probs)\n","\n","# For each true class, compute the mean probability vector\n","mean_probs = []\n","for t in range(class_count):\n","    if probs_by_class[t]:\n","        mean = np.stack(probs_by_class[t]).mean(axis=0)\n","    else:\n","        mean = np.zeros(class_count)  # if no samples for this class\n","    mean_probs.append(mean)\n","\n","# Convert to 2D array: [true_class, predicted_class]\n","matrix = np.stack(mean_probs)  # shape [C, C]\n","\n","# Plot heatmap\n","fig, ax = plt.subplots(figsize=(9, 6))\n","im = ax.imshow(matrix, cmap='viridis', aspect='auto')\n","\n","plt.colorbar(im, ax=ax, label='Avg Predicted Probability')\n","ax.set_title(\"Mean Predicted Probabilities by True Class\")\n","ax.set_xlabel(\"Predicted Class\")\n","ax.set_ylabel(\"True Class\")\n","ax.set_xticks(range(class_count))\n","ax.set_yticks(range(class_count))\n","ax.set_yticklabels(['%s [%d]' % (label_name_lookup[i], i) for i in range(class_count)])\n","plt.tight_layout()\n","plt.show()\n","\n"]},{"cell_type":"code","execution_count":null,"id":"25618be6","metadata":{"id":"25618be6"},"outputs":[],"source":["# Confusion matrix.\n","\n","class_count = max(d[\"true_label\"] for d in cases) + 1\n","print(class_count)\n","cmat = np.zeros((class_count, class_count))\n","\n","for d in cases:\n","    true_label = d[\"true_label\"]\n","    pred_label = np.argmax(d[\"probs\"])\n","    cmat[true_label, pred_label] += 1\n","\n","cmat = np.sqrt(cmat)\n","\n","# Plot heatmap\n","fig, ax = plt.subplots(figsize=(12, 8))\n","im = ax.imshow(cmat, cmap='viridis', aspect='auto')\n","\n","plt.colorbar(im, ax=ax, label='Number Of Cases')\n","ax.set_title(\"Confusion Matrix\")\n","ax.set_xlabel(\"Predicted Class\")\n","ax.set_ylabel(\"True Class\")\n","ax.set_xticks(range(class_count))\n","ax.set_yticks(range(class_count))\n","ax.set_yticklabels([label_name_lookup[i] for i in range(class_count)])\n","plt.tight_layout()\n","plt.show()\n"]},{"cell_type":"code","execution_count":null,"id":"QkwGn1oASpdV","metadata":{"id":"QkwGn1oASpdV"},"outputs":[],"source":["# Accuracy stats\n","\n","from sklearn.metrics import top_k_accuracy_score, f1_score\n","\n","y_true = np.array([d[\"true_label\"] for d in cases])\n","y_pred = np.array([np.argmax(d[\"probs\"]) for d in cases])\n","y_prob = np.vstack([d[\"probs\"] for d in cases])\n","\n","all_labels = list(range(22))\n","print('top-1 accuracy: %.4f' % top_k_accuracy_score(y_true, y_prob, k=1, labels=all_labels))\n","print('top-2 accuracy: %.4f' % top_k_accuracy_score(y_true, y_prob, k=2, labels=all_labels))\n","print('top-3 accuracy: %.4f' % top_k_accuracy_score(y_true, y_prob, k=3, labels=all_labels))\n","print('top-4 accuracy: %.4f' % top_k_accuracy_score(y_true, y_prob, k=4, labels=all_labels))\n","print('top-5 accuracy: %.4f' % top_k_accuracy_score(y_true, y_prob, k=5, labels=all_labels))\n","print('f1 score: %.4f' % f1_score(y_true, y_pred, average='macro'))\n"]},{"cell_type":"markdown","id":"G6ijwhjy6XZP","metadata":{"id":"G6ijwhjy6XZP"},"source":["## Check consistency with respect to randomization."]},{"cell_type":"code","execution_count":null,"id":"A7NznUeG7vCQ","metadata":{"id":"A7NznUeG7vCQ"},"outputs":[],"source":["# Get a \"batch\" consisting of one instance.\n","dataset = VergeDataset(val_tiles, n_classes, mask_fraction=0.15)\n","batch = [dataset[k] for k in [3]]\n","batch_features, batch_labels, batch_attention_mask = collate_fn(batch)\n","batch_labels\n"]},{"cell_type":"code","execution_count":null,"id":"RDFrypwa8fam","metadata":{"id":"RDFrypwa8fam"},"outputs":[],"source":["# Get the logits for that batch.\n","model.to(device)\n","batch_features = batch_features.to(device)\n","batch_attention_mask = batch_attention_mask.to(device)\n","logits = model(batch_features, batch_attention_mask)\n","print(logits.shape)"]},{"cell_type":"code","execution_count":null,"id":"noz6mCxM9teW","metadata":{"id":"noz6mCxM9teW"},"outputs":[],"source":["# Get a random permutation to be applied to the rows of the batch.\n","# Permute every row except the first -- we will use that as a reference.\n","perm = torch.concat((\n","    torch.tensor([0]),\n","    torch.randperm(batch_features.shape[1] - 1) + 1\n","))\n","print(perm)"]},{"cell_type":"code","execution_count":null,"id":"_1CSwU3m9-Uy","metadata":{"id":"_1CSwU3m9-Uy"},"outputs":[],"source":["# Apply the permutation to the features and re-run the model.\n","permuted_features = batch_features.clone()\n","permuted_features = permuted_features[:, perm]\n","permuted_features.to(device)\n","permuted_logits = model(permuted_features, batch_attention_mask)\n","print(permuted_logits.shape)"]},{"cell_type":"code","execution_count":null,"id":"SqSCEgfW-DbS","metadata":{"id":"SqSCEgfW-DbS"},"outputs":[],"source":["# Extract the corresponding logits from the original and permuted result.\n","a_index = 0\n","b_index = torch.where(perm == a_index)[0][0].item()\n","print(a_index, b_index)\n","a = logits[0, a_index]\n","b = permuted_logits[0, b_index]\n","print(a)\n","print(b)"]},{"cell_type":"code","execution_count":null,"id":"mWDemHx2-jwe","metadata":{"id":"mWDemHx2-jwe"},"outputs":[],"source":["import plotly\n","from plotly.subplots import make_subplots\n","from plotly.graph_objects import Scatter\n","\n","aa = torch.Tensor.cpu(a).detach().numpy()\n","bb = torch.Tensor.cpu(b).detach().numpy()\n","\n","fig = make_subplots(rows=1, cols=1)\n","n = aa.shape[0]\n","xx = np.arange(n)\n","\n","trace = Scatter(x=xx, y=aa, name='a', mode='markers+lines')\n","fig.add_trace(trace, row=1, col=1)\n","\n","trace = Scatter(x=xx, y=bb, name='b', mode='markers+lines')\n","fig.add_trace(trace, row=1, col=1)\n","\n","fig.show()"]},{"cell_type":"code","execution_count":null,"id":"hnABe4I8zNOx","metadata":{"id":"hnABe4I8zNOx"},"outputs":[],"source":["batch_features[0, a_index, :] - permuted_features[0, b_index, :]"]},{"cell_type":"code","execution_count":null,"id":"RKBB47lHO7Vr","metadata":{"id":"RKBB47lHO7Vr"},"outputs":[],"source":["x = batch_features\n","x_perm = x.clone()\n","x_perm[:, [0, 1], :] = x_perm[:, [1, 0], :]  # Swap two entities in each sample\n","logits_orig = model(x, batch_attention_mask)\n","logits_perm = model(x_perm, batch_attention_mask)\n","\n","print((logits_orig - logits_perm).abs().max())  # Should be > 0 for non-invariant models\n"]},{"cell_type":"code","execution_count":null,"id":"41f79da7-133d-4f42-ab8e-77eb248cc382","metadata":{"id":"41f79da7-133d-4f42-ab8e-77eb248cc382"},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"A100","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.4"}},"nbformat":4,"nbformat_minor":5}