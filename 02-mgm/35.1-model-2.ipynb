{"cells":[{"cell_type":"markdown","id":"e86b8916-bdd0-46e6-8195-8de0a4a06ab4","metadata":{"id":"e86b8916-bdd0-46e6-8195-8de0a4a06ab4"},"source":["### VERGE: Vector-mode Regional Geospatial Encoding\n","# Masked Geospatial Model Implementation\n","\n","Here we build and train a \"masked geospatial model\".\n","This is a model in which each input is a set of encoded geospatial entities,\n","consisting of a concatenation of a multi-point proximity encoding and a one-hot label vector.\n","Modeling consists of masking the labels for a random selection of entities,\n","passing the data through an encoder-based architecutre to predicte the labels of masked entities.\n","The idea is that the encodings then capture information about the region.\n"]},{"cell_type":"markdown","id":"8M2z1JqEbum-","metadata":{"id":"8M2z1JqEbum-"},"source":["## Processing Setup"]},{"cell_type":"code","execution_count":1,"id":"SDCVXcwwbuNz","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":638,"status":"ok","timestamp":1753815503476,"user":{"displayName":"John Collins","userId":"16643596247369517939"},"user_tz":240},"id":"SDCVXcwwbuNz","outputId":"6b354b78-150b-4de6-ce3a-bd73c158a0f1"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["# Google colab setup\n","import os\n","from google.colab import drive\n","drive.mount('/content/drive')\n","project_home = '/content/drive/MyDrive/Projects/verge'\n","os.chdir(project_home)"]},{"cell_type":"code","execution_count":2,"id":"rexpq0-tAp12","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":10916,"status":"ok","timestamp":1753815514390,"user":{"displayName":"John Collins","userId":"16643596247369517939"},"user_tz":240},"id":"rexpq0-tAp12","outputId":"389f6b1d-8305-472a-b7ef-0791faf3ea37"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: geo_encodings in /usr/local/lib/python3.11/dist-packages (1.0.4)\n","Requirement already satisfied: shapely in /usr/local/lib/python3.11/dist-packages (from geo_encodings) (2.1.1)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from geo_encodings) (1.16.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from geo_encodings) (2.0.2)\n"]}],"source":["!pip install geo_encodings"]},{"cell_type":"code","execution_count":3,"id":"7CvwllV6ATky","metadata":{"executionInfo":{"elapsed":4,"status":"ok","timestamp":1753815514430,"user":{"displayName":"John Collins","userId":"16643596247369517939"},"user_tz":240},"id":"7CvwllV6ATky"},"outputs":[],"source":["# Local processing setup\n","# project_home = '..'"]},{"cell_type":"markdown","id":"0cXRuWo0AWx0","metadata":{"id":"0cXRuWo0AWx0"},"source":["## Source"]},{"cell_type":"code","execution_count":4,"id":"78ad6c64-0b24-4315-ae3c-6b3b21f6175d","metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1753815514437,"user":{"displayName":"John Collins","userId":"16643596247369517939"},"user_tz":240},"id":"78ad6c64-0b24-4315-ae3c-6b3b21f6175d"},"outputs":[],"source":["# The name of the ROI to use.\n","roi_name = 'newengland'\n","\n","# The name of the general-purpose data directory.\n","data_home = '%s/data' % (project_home)\n","\n","# The name of the ROI-specific data directory.\n","roi_home = '%s/data/%s' % (project_home, roi_name)"]},{"cell_type":"markdown","id":"EJh-qkB0byEf","metadata":{"id":"EJh-qkB0byEf"},"source":["## Setup"]},{"cell_type":"code","execution_count":5,"id":"b54d7995-33a4-44b6-a248-4d97c86ce57c","metadata":{"executionInfo":{"elapsed":4285,"status":"ok","timestamp":1753815518725,"user":{"displayName":"John Collins","userId":"16643596247369517939"},"user_tz":240},"id":"b54d7995-33a4-44b6-a248-4d97c86ce57c"},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","import glob\n","import pickle\n","import os\n","import torch\n","import torch.nn as nn\n","import torch.utils\n","import torch.utils.data\n","from torch.utils.data import DataLoader\n","import copy\n","import json\n","from geo_encodings import MPPEncoder\n","\n","import sys\n","sys.path.append(project_home)\n","from utils.geo_transformer_mem import VergeDataset, verge_collate_fn, GeospatialTransformer\n"]},{"cell_type":"code","source":["np.random.seed(5)"],"metadata":{"id":"yYw_cY2ijTbZ"},"id":"yYw_cY2ijTbZ","execution_count":null,"outputs":[]},{"cell_type":"markdown","id":"445ca7e3-ead1-4ddd-b908-e3ecf2d2aef2","metadata":{"id":"445ca7e3-ead1-4ddd-b908-e3ecf2d2aef2"},"source":["## Parameters"]},{"cell_type":"code","execution_count":6,"id":"bcee54dc-61bc-4044-bdb1-176d262ee420","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":41,"status":"ok","timestamp":1753815518769,"user":{"displayName":"John Collins","userId":"16643596247369517939"},"user_tz":240},"id":"bcee54dc-61bc-4044-bdb1-176d262ee420","outputId":"67632184-94ab-426f-82e8-c5c837e288ad"},"outputs":[{"output_type":"stream","name":"stdout","text":["400 elements in encodings\n"]}],"source":["# Read the ROI definition.\n","fname = '%s/roi.json' % roi_home\n","with open(fname) as source:\n","    roi = json.load(source)\n","\n","tile_size = roi['tile_size']\n","encoding_resolution = roi['encoding_resolution']\n","\n","# We need the dimension of the encoding.\n","encoder = MPPEncoder(\n","    region=[0, 0, tile_size, tile_size],\n","    resolution=encoding_resolution,\n","    center=True\n",")\n","geo_encoding_dim = len(encoder)\n","print('%d elements in encodings' % geo_encoding_dim)\n"]},{"cell_type":"code","execution_count":7,"id":"ee168238-1ed3-44c8-af9b-c1907aadfab2","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":15,"status":"ok","timestamp":1753815518825,"user":{"displayName":"John Collins","userId":"16643596247369517939"},"user_tz":240},"id":"ee168238-1ed3-44c8-af9b-c1907aadfab2","outputId":"d35f2922-6c81-4f3a-f183-74738696734b"},"outputs":[{"output_type":"stream","name":"stdout","text":["using device cuda\n"]}],"source":["# A unique identifier for this run. This will be a component of any\n","# output file names.\n","run_id = '007'\n","\n","# What type of device to train on.\n","device = 'cuda' if torch.cuda.is_available() else 'cpu'\n","print('using device', device)\n","\n","# Fraction of cases to use for training.\n","train_fraction = 0.8\n","\n","# Number of epochs to run.\n","epoch_count = 5"]},{"cell_type":"markdown","id":"ae4c1f54-443b-4820-ae36-b00ed6d575d1","metadata":{"id":"ae4c1f54-443b-4820-ae36-b00ed6d575d1"},"source":["## Preliminaries"]},{"cell_type":"code","execution_count":8,"id":"d216238e-a075-4a1d-81cf-3269d8c82fb8","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":81,"status":"ok","timestamp":1753815518940,"user":{"displayName":"John Collins","userId":"16643596247369517939"},"user_tz":240},"id":"d216238e-a075-4a1d-81cf-3269d8c82fb8","outputId":"1ec45b9e-6a92-430f-acea-9ad4e6d80f8e"},"outputs":[{"output_type":"stream","name":"stdout","text":["22 labels in this dataset\n"]}],"source":["# Read the list of labels.\n","fname = '%s/labels.csv' % data_home\n","labels = pd.read_csv(fname)\n","n_classes = len(labels)\n","print('%d labels in this dataset' % n_classes)\n","\n","label_id_lookup = {\n","    z['label']: z['id']\n","    for z in labels.to_dict('records')\n","}\n","\n","label_name_lookup = {\n","    z['id']: z['label']\n","    for z in labels.to_dict('records')\n","}"]},{"cell_type":"code","execution_count":9,"id":"2ea121c2-9ddf-4180-abff-2f5c7c6a9888","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2ea121c2-9ddf-4180-abff-2f5c7c6a9888","executionInfo":{"status":"ok","timestamp":1753815518941,"user_tz":240,"elapsed":70,"user":{"displayName":"John Collins","userId":"16643596247369517939"}},"outputId":"6b958480-09de-4556-8823-12f80171cbbb"},"outputs":[{"output_type":"stream","name":"stdout","text":["22 class info records\n"]}],"source":["# Read the file that gives class probabilities.\n","fname = '%s/class_info.csv' % roi_home\n","class_info = pd.read_csv(fname)\n","print('%d class info records' % len(class_info))"]},{"cell_type":"markdown","id":"qCD2RJu73g26","metadata":{"id":"qCD2RJu73g26"},"source":["## Load data\n","The data exist as NPZ files containing features and label vectors.\n","Each is in a sub-folder for its AOI.\n","We want to divide into train / validation splits according to the AOI,\n","not the individual tile. This reduces autocorrelation effects that could\n","bias performance assessments."]},{"cell_type":"code","execution_count":10,"id":"2a53d850-0eca-4112-9c9a-c1661846aa5d","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2a53d850-0eca-4112-9c9a-c1661846aa5d","executionInfo":{"status":"ok","timestamp":1753815519259,"user_tz":240,"elapsed":322,"user":{"displayName":"John Collins","userId":"16643596247369517939"}},"outputId":"e046b827-c5fe-4c5c-d4d3-8631832f4550"},"outputs":[{"output_type":"stream","name":"stdout","text":["2524 training instances\n","548 validation instances\n"]}],"source":["# Get a list of AOI folders.\n","globstring = '%s/encodings/*' % roi_home\n","aoi_dnames = glob.glob(globstring)\n","\n","# Loop over those, adding their files to either the train or val sets.\n","train_fnames = []\n","val_fnames = []\n","split_records = []\n","np.random.seed(5)\n","for aoi_dname in aoi_dnames:\n","    globstring = '%s/*.npz' % aoi_dname\n","    tile_fnames = glob.glob(globstring)\n","\n","    # Hack: downsample the tile file names.\n","    tile_fnames = list(np.random.choice(tile_fnames, int(len(tile_fnames) * 0.2)))\n","\n","    if np.random.random() < train_fraction:\n","        split = 'train'\n","        train_fnames += tile_fnames\n","    else:\n","        split = 'val'\n","        val_fnames += tile_fnames\n","    # print('added %d files to the %s set' % (len(tile_fnames), split))\n","    split_records.append({'aoi': aoi_dname, 'split': split})\n","\n","print('%d training instances' % len(train_fnames))\n","print('%d validation instances' % len(val_fnames))\n","\n","# Save the split records\n","fname = '%s/splits-%s.csv' % (roi_home, run_id)\n","pd.DataFrame(split_records).to_csv(fname, index=False)"]},{"cell_type":"code","execution_count":11,"id":"11cd86c9-551f-42f7-a303-c8f99af4c9e1","metadata":{"id":"11cd86c9-551f-42f7-a303-c8f99af4c9e1","executionInfo":{"status":"ok","timestamp":1753815519266,"user_tz":240,"elapsed":6,"user":{"displayName":"John Collins","userId":"16643596247369517939"}}},"outputs":[],"source":["# # Test that.\n","# dataset = VergeDataset(train_tiles, n_classes, mask_fraction=0.15)\n","# batch = [dataset[k] for k in [0, 12, 17, 23]]\n","# batch_features, batch_labels, batch_attention_mask = verge_collate_fn(batch)\n","# print('test:')\n","# print('batch_features.shape', batch_features.shape)\n","# print('batch_labels.shape', batch_labels.shape)\n","# print('batch_attention_mask.shape', batch_attention_mask.shape)\n"]},{"cell_type":"code","execution_count":12,"id":"59162f11-1eca-4998-8cf0-0371d308bea5","metadata":{"id":"59162f11-1eca-4998-8cf0-0371d308bea5","colab":{"base_uri":"https://localhost:8080/","height":384},"executionInfo":{"status":"error","timestamp":1753815960737,"user_tz":240,"elapsed":441469,"user":{"displayName":"John Collins","userId":"16643596247369517939"}},"outputId":"b89f9a60-a955-4a9c-a232-630e66e37b66"},"outputs":[{"output_type":"stream","name":"stdout","text":["loading instance 0 / 2524\n","loading instance 1000 / 2524\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/tmp/ipython-input-12-1509347637.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# Initialize training and validation datasets.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mtrain_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVergeDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_fnames\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_classes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask_fraction\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.15\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_prob\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_prob_lookup\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m train_dataloader = DataLoader(\n\u001b[1;32m     10\u001b[0m     \u001b[0mtrain_dataset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/content/drive/MyDrive/Projects/verge/utils/geo_transformer_mem.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, instance_fnames, n_classes, mask_fraction, class_prob)\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mk\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m1000\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'loading instance %d / %d'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minstance_fnames\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m             \u001b[0mloaded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minstance_fname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minstances\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloaded\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/numpy/lib/_npyio_impl.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(file, mmap_mode, allow_pickle, fix_imports, encoding, max_header_size)\u001b[0m\n\u001b[1;32m    460\u001b[0m         \u001b[0m_ZIP_SUFFIX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mb'PK\\x05\\x06'\u001b[0m  \u001b[0;31m# empty zip files start with this\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    461\u001b[0m         \u001b[0mN\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMAGIC_PREFIX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 462\u001b[0;31m         \u001b[0mmagic\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    463\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mmagic\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    464\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mEOFError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"No data left in file\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["# The dataset constructor requires a lookup table for class probabilities.\n","class_prob_lookup = {\n","    z['label']: z['prob']\n","    for z in class_info.to_dict('records')\n","}\n","\n","# Initialize training and validation datasets.\n","train_dataset = VergeDataset(train_fnames, n_classes, mask_fraction=0.15, class_prob=class_prob_lookup)\n","train_dataloader = DataLoader(\n","    train_dataset,\n","    batch_size=64, # Tune depending on GPU memory\n","    shuffle=True,\n","    num_workers=4,\n","    collate_fn=verge_collate_fn,\n","    drop_last=False\n",")\n","\n","val_dataset = VergeDataset(val_fnames, n_classes, mask_fraction=0.15, class_prob=class_prob_lookup)\n","val_dataloader = DataLoader(\n","    val_dataset,\n","    batch_size=64, # Tune depending on GPU memory\n","    shuffle=True,\n","    num_workers=4,\n","    collate_fn=verge_collate_fn,\n","    drop_last=False\n",")"]},{"cell_type":"markdown","id":"419b685c-980f-42d5-8d7a-a195b3f8705e","metadata":{"id":"419b685c-980f-42d5-8d7a-a195b3f8705e"},"source":["## Model definition"]},{"cell_type":"code","execution_count":null,"id":"daedea23-2671-49d1-85a8-ec5c557a8ea2","metadata":{"id":"daedea23-2671-49d1-85a8-ec5c557a8ea2","executionInfo":{"status":"aborted","timestamp":1753815960882,"user_tz":240,"elapsed":458137,"user":{"displayName":"John Collins","userId":"16643596247369517939"}}},"outputs":[],"source":["model = GeospatialTransformer(\n","    feature_dim = geo_encoding_dim + n_classes,\n","    model_dim=128,\n","    num_heads=4,\n","    num_layers=5,\n","    num_classes=n_classes,\n","    dropout=0.2\n",")\n","n_param = sum(p.numel() for p in model.parameters() if p.requires_grad)\n","print('%d trainable parameters in model' % n_param)"]},{"cell_type":"code","execution_count":null,"id":"82d31215-685a-42f0-a834-c29f2b2c2b83","metadata":{"id":"82d31215-685a-42f0-a834-c29f2b2c2b83","executionInfo":{"status":"aborted","timestamp":1753815960886,"user_tz":240,"elapsed":458140,"user":{"displayName":"John Collins","userId":"16643596247369517939"}}},"outputs":[],"source":["# Testing\n","# dataset = VergeDataset(train_tiles, n_classes, mask_fraction=0.15)\n","# dataloader = DataLoader(\n","#     dataset,\n","#     batch_size=2,            # Tune depending on GPU memory\n","#     shuffle=True,\n","#     collate_fn=verge_collate_fn,   # Key for padding variable-length instances\n","#     drop_last=False\n","# )\n","\n","# features, labels, attention_mask = dataloader.__iter__().__next__()\n","# print(features.shape, labels.shape, attention_mask.shape)"]},{"cell_type":"code","execution_count":null,"id":"927cKIPZbfp3","metadata":{"id":"927cKIPZbfp3","executionInfo":{"status":"aborted","timestamp":1753815960888,"user_tz":240,"elapsed":458142,"user":{"displayName":"John Collins","userId":"16643596247369517939"}}},"outputs":[],"source":["# model(features, attention_mask)"]},{"cell_type":"markdown","id":"fa310216-b622-42e2-a551-322943108993","metadata":{"id":"fa310216-b622-42e2-a551-322943108993"},"source":["### Training loop"]},{"cell_type":"code","execution_count":null,"id":"80a432a9-dee4-42c8-a068-61d31492436a","metadata":{"id":"80a432a9-dee4-42c8-a068-61d31492436a","executionInfo":{"status":"aborted","timestamp":1753815960890,"user_tz":240,"elapsed":458143,"user":{"displayName":"John Collins","userId":"16643596247369517939"}}},"outputs":[],"source":["model.to(device)\n","optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n","criterion = nn.CrossEntropyLoss(ignore_index=-100)\n","\n","losses = []\n","\n","model.train()\n","for epoch in range(epoch_count):\n","\n","    # Training.\n","    model.train()\n","    ibatch = 0\n","    for features, labels, attention_mask in train_dataloader:\n","        ibatch += 1\n","        if ibatch % 10 == 0:\n","            print('epoch %d, batch %d' % (epoch, ibatch))\n","\n","        features = features.to(device)\n","        labels = labels.to(device)\n","        attention_mask = attention_mask.to(device)\n","\n","        logits = model(features, attention_mask)\n","        loss = criterion(\n","            logits.view(-1, n_classes),\n","            labels.view(-1)\n","        )\n","\n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","\n","    # Validation loss\n","    model.eval()\n","    with torch.no_grad():\n","        for features, labels, attention_mask in val_dataloader:\n","            features = features.to(device)\n","            labels = labels.to(device)\n","            attention_mask = attention_mask.to(device)\n","            logits = model(features, attention_mask)\n","            val_loss = criterion(\n","                logits.view(-1, n_classes),\n","                labels.view(-1)\n","            )\n","\n","    losses.append({\n","        'epoch': epoch,\n","        'train_loss': loss.item(),\n","        'val_loss': val_loss.item()\n","    })\n","\n","    print(f\"Epoch {epoch+1}, train loss: {loss.item():.4f}, val_loss: {val_loss.item():.4f}\")\n"]},{"cell_type":"code","execution_count":null,"id":"L253y-1viYNM","metadata":{"id":"L253y-1viYNM","executionInfo":{"status":"aborted","timestamp":1753815960892,"user_tz":240,"elapsed":458144,"user":{"displayName":"John Collins","userId":"16643596247369517939"}}},"outputs":[],"source":["# Save the model.\n","model_fname = '%s/model-%s' % (roi_home, run_id)\n","torch.save(model, model_fname)\n","print('saved %s' % model_fname)"]},{"cell_type":"markdown","id":"08a93715-1774-4bc4-8813-7cddbb14fc96","metadata":{"id":"08a93715-1774-4bc4-8813-7cddbb14fc96"},"source":["## Loss history"]},{"cell_type":"code","execution_count":null,"id":"c5d2246e-df72-48f6-98fa-8be691be1242","metadata":{"id":"c5d2246e-df72-48f6-98fa-8be691be1242","executionInfo":{"status":"aborted","timestamp":1753815960894,"user_tz":240,"elapsed":458146,"user":{"displayName":"John Collins","userId":"16643596247369517939"}}},"outputs":[],"source":["import plotly\n","from plotly.subplots import make_subplots\n","from plotly.graph_objects import Scatter\n","\n","epochs = [d['epoch'] for d in losses]\n","train_losses = [d['train_loss'] for d in losses]\n","val_losses = [d['val_loss'] for d in losses]\n","\n","fig = make_subplots(rows=1, cols=1)\n","trace = Scatter(\n","    x=epochs, y=train_losses, name='training loss',\n","    mode='markers+lines', marker_color='blue'\n",")\n","fig.append_trace(trace, 1, 1)\n","\n","trace = Scatter(\n","    x=epochs, y=val_losses, name='validation loss',\n","    mode='markers+lines', marker_color='green'\n",")\n","fig.append_trace(trace, 1, 1)\n","\n","fig"]},{"cell_type":"markdown","id":"c10079b1","metadata":{"id":"c10079b1"},"source":["## Validation Visualization"]},{"cell_type":"code","execution_count":null,"id":"9fb80ef4","metadata":{"id":"9fb80ef4","executionInfo":{"status":"aborted","timestamp":1753815960895,"user_tz":240,"elapsed":458146,"user":{"displayName":"John Collins","userId":"16643596247369517939"}}},"outputs":[],"source":["# Process the validation dataset, getting the class probability predictions\n","# for every instance.\n","model.to(device)\n","cases = []\n","model.eval()\n","for features, labels, attention_mask in val_dataloader:\n","\n","    features = features.to(device)\n","    attention_mask = attention_mask.to(device)\n","    labels = labels.to(device)\n","\n","    logits = model(features, attention_mask)\n","\n","    batch_size = logits.shape[0]\n","    for i in range(batch_size):\n","        case_logits = logits[i]\n","        case_probs = torch.softmax(case_logits, dim=1)\n","        case_labels = labels[i]\n","        entity_count = len(case_labels)\n","        for k in range(entity_count):\n","            if case_labels[k].item() >= 0: # Skips the \"-100\" labels.\n","                cases.append({\n","                    'true_label': case_labels[k].item(),\n","                    'probs': torch.Tensor.cpu(case_probs[k, :]).detach().numpy()\n","                })\n","\n","print('compiled prediction probabilities for %d validation instances' % len(cases))"]},{"cell_type":"code","execution_count":null,"id":"dd2752ef","metadata":{"id":"dd2752ef","executionInfo":{"status":"aborted","timestamp":1753815960897,"user_tz":240,"elapsed":458148,"user":{"displayName":"John Collins","userId":"16643596247369517939"}}},"outputs":[],"source":["import numpy as np\n","import matplotlib.pyplot as plt\n","from collections import defaultdict\n","\n","class_count = max(d[\"true_label\"] for d in cases) + 1\n","probs_by_class = defaultdict(list)\n","\n","for d in cases:\n","    label = d[\"true_label\"]\n","    probs = np.array(d[\"probs\"])\n","    probs_by_class[label].append(probs)\n","\n","# For each true class, compute the mean probability vector\n","mean_probs = []\n","for t in range(class_count):\n","    if probs_by_class[t]:\n","        mean = np.stack(probs_by_class[t]).mean(axis=0)\n","    else:\n","        mean = np.zeros(class_count)  # if no samples for this class\n","    mean_probs.append(mean)\n","\n","# Convert to 2D array: [true_class, predicted_class]\n","matrix = np.stack(mean_probs)  # shape [C, C]\n","\n","# Plot heatmap\n","fig, ax = plt.subplots(figsize=(9, 6))\n","im = ax.imshow(matrix, cmap='viridis', aspect='auto')\n","\n","plt.colorbar(im, ax=ax, label='Avg Predicted Probability')\n","ax.set_title(\"Mean Predicted Probabilities by True Class\")\n","ax.set_xlabel(\"Predicted Class\")\n","ax.set_ylabel(\"True Class\")\n","ax.set_xticks(range(class_count))\n","ax.set_yticks(range(class_count))\n","ax.set_yticklabels([label_name_lookup[i] for i in range(class_count)])\n","plt.tight_layout()\n","plt.show()"]},{"cell_type":"code","execution_count":null,"id":"25618be6","metadata":{"id":"25618be6","executionInfo":{"status":"aborted","timestamp":1753815960938,"user_tz":240,"elapsed":458188,"user":{"displayName":"John Collins","userId":"16643596247369517939"}}},"outputs":[],"source":["# class_count = max(d[\"true_label\"] for d in cases) + 1\n","# print(class_count)\n","# cmat = np.zeros((class_count, class_count))\n","\n","# for d in cases:\n","#     true_label = d[\"true_label\"]\n","#     pred_label = np.argmax(d[\"probs\"])\n","#     cmat[true_label, pred_label] += 1\n","\n","# cmat = np.sqrt(cmat)\n","\n","# # Plot heatmap\n","# fig, ax = plt.subplots(figsize=(12, 8))\n","# im = ax.imshow(cmat, cmap='viridis', aspect='auto')\n","\n","# plt.colorbar(im, ax=ax, label='Number Of Cases')\n","# ax.set_title(\"Confusion Matrix\")\n","# ax.set_xlabel(\"Predicted Class\")\n","# ax.set_ylabel(\"True Class\")\n","# ax.set_xticks(range(class_count))\n","# ax.set_yticks(range(class_count))\n","# ax.set_yticklabels(['%s [%d]' % (label_name_lookup[i], i) for i in range(class_count)])\n","# plt.tight_layout()\n","# plt.show()\n"]},{"cell_type":"code","source":[],"metadata":{"id":"t9ATpZ6j-6Gc","executionInfo":{"status":"aborted","timestamp":1753815960939,"user_tz":240,"elapsed":458189,"user":{"displayName":"John Collins","userId":"16643596247369517939"}}},"id":"t9ATpZ6j-6Gc","execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"id":"7acc18b7","metadata":{"executionInfo":{"elapsed":458190,"status":"aborted","timestamp":1753815960941,"user":{"displayName":"John Collins","userId":"16643596247369517939"},"user_tz":240},"id":"7acc18b7"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"id":"899fd353-0e6e-42e7-aaf1-49e46d3f1720","metadata":{"executionInfo":{"elapsed":458191,"status":"aborted","timestamp":1753815960942,"user":{"displayName":"John Collins","userId":"16643596247369517939"},"user_tz":240},"id":"899fd353-0e6e-42e7-aaf1-49e46d3f1720"},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.4"}},"nbformat":4,"nbformat_minor":5}